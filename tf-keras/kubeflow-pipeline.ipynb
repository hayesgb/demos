{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow-Keras Classifier and Transfer Learning Using Serverless Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mlrun``` is an open-source Python package that provides a framework for running machine learning tasks transparently in multiple, scalable, runtime environments.  ```mlrun``` provides tracking of code, metadata, inputs, outputs and the results of machine learning pipelines. \n",
    "\n",
    "In this notebook we\"ll compose a pipeline that deploys a classifier model, and uses it as the input in either evaluation, inference, or retrain steps.\n",
    "\n",
    "\n",
    "1. [Setup](#Setup)\n",
    "2. [Utilties](#utilities)\n",
    "3. [Components](#Components)\n",
    "     * [acquire](#acquire)\n",
    "     * [transform](#transform)\n",
    "     * [tsdb-ingest](#tsdb-ingest)\n",
    "     * [tsdb-query](#tsdb-query)\n",
    "     * [split](#split)\n",
    "     * [train](#train)\n",
    "     * [test](#test)\n",
    "     * [feature-map](#feature-map)\n",
    "     * [retrain](#transfer%20learning)\n",
    "4. [Test](#testing)\n",
    "5. [Compose](#image)\n",
    "6. [Run](#run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following will reinstall the latest development version of ```mlrun```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling mlrun-0.3.3:\n",
      "  Successfully uninstalled mlrun-0.3.3\n",
      "Collecting git+https://github.com/mlrun/mlrun.git@development\n",
      "  Cloning https://github.com/mlrun/mlrun.git (to revision development) to /tmp/pip-req-build-85ncuvz0\n",
      "Branch development set up to track remote branch development from origin.\n",
      "Switched to a new branch 'development'\n",
      "Requirement already satisfied: Flask>=1.1.1 in /User/.pythonlibs/lib/python3.6/site-packages (from mlrun==0.3.3) (1.1.1)\n",
      "Requirement already satisfied: GitPython>=2.1.0 in /conda/lib/python3.6/site-packages (from mlrun==0.3.3) (3.0.4)\n",
      "Requirement already satisfied: aiohttp>=3.5.0 in /User/.pythonlibs/lib/python3.6/site-packages (from mlrun==0.3.3) (3.6.2)\n",
      "Requirement already satisfied: boto3>=1.9 in /conda/lib/python3.6/site-packages (from mlrun==0.3.3) (1.10.0)\n",
      "Requirement already satisfied: click>=7.0 in /conda/lib/python3.6/site-packages (from mlrun==0.3.3) (7.0)\n",
      "Requirement already satisfied: gunicorn==19.9.0 in /User/.pythonlibs/lib/python3.6/site-packages (from mlrun==0.3.3) (19.9.0)\n",
      "Requirement already satisfied: kubernetes>=9.0.0 in /User/.pythonlibs/lib/python3.6/site-packages (from mlrun==0.3.3) (9.0.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.0.0 in /User/.pythonlibs/lib/python3.6/site-packages (from mlrun==0.3.3) (1.2.1)\n",
      "Requirement already satisfied: nuclio-jupyter>=0.7.6 in /conda/lib/python3.6/site-packages (from mlrun==0.3.3) (0.7.6)\n",
      "Requirement already satisfied: nuclio-sdk>=0.0.3 in /conda/lib/python3.6/site-packages (from mlrun==0.3.3) (0.0.5)\n",
      "Requirement already satisfied: pandas>=0.23.0 in /User/.pythonlibs/lib/python3.6/site-packages (from mlrun==0.3.3) (0.25.3)\n",
      "Requirement already satisfied: pyyaml>=5.1.0 in /conda/lib/python3.6/site-packages (from mlrun==0.3.3) (5.1.2)\n",
      "Requirement already satisfied: requests>=2.20.1 in /conda/lib/python3.6/site-packages (from mlrun==0.3.3) (2.22.0)\n",
      "Collecting sqlalchemy==1.3.11 (from mlrun==0.3.3)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/5c/0e1d7ad0ca52544bb12f9cb8d5cc454af45821c92160ffedd38db0a317f6/SQLAlchemy-1.3.11.tar.gz (6.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 6.0MB 7.3MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: tabulate>=0.8.0 in /User/.pythonlibs/lib/python3.6/site-packages (from mlrun==0.3.3) (0.8.3)\n",
      "Requirement already satisfied: kfp>=0.1.29 in /User/.pythonlibs/lib/python3.6/site-packages (from mlrun==0.3.3) (0.1.37)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /User/.pythonlibs/lib/python3.6/site-packages (from Flask>=1.1.1->mlrun==0.3.3) (0.16.0)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /User/.pythonlibs/lib/python3.6/site-packages (from Flask>=1.1.1->mlrun==0.3.3) (1.1.0)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /conda/lib/python3.6/site-packages (from Flask>=1.1.1->mlrun==0.3.3) (2.10.3)\n",
      "Requirement already satisfied: gitdb2>=2.0.0 in /conda/lib/python3.6/site-packages (from GitPython>=2.1.0->mlrun==0.3.3) (2.0.6)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /User/.pythonlibs/lib/python3.6/site-packages (from aiohttp>=3.5.0->mlrun==0.3.3) (3.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /User/.pythonlibs/lib/python3.6/site-packages (from aiohttp>=3.5.0->mlrun==0.3.3) (1.4.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5; python_version < \"3.7\" in /User/.pythonlibs/lib/python3.6/site-packages (from aiohttp>=3.5.0->mlrun==0.3.3) (3.7.4.1)\n",
      "Requirement already satisfied: multidict<5.0,>=4.5 in /User/.pythonlibs/lib/python3.6/site-packages (from aiohttp>=3.5.0->mlrun==0.3.3) (4.6.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /conda/lib/python3.6/site-packages (from aiohttp>=3.5.0->mlrun==0.3.3) (19.3.0)\n",
      "Requirement already satisfied: chardet<4.0,>=2.0 in /conda/lib/python3.6/site-packages (from aiohttp>=3.5.0->mlrun==0.3.3) (3.0.4)\n",
      "Requirement already satisfied: idna-ssl>=1.0; python_version < \"3.7\" in /User/.pythonlibs/lib/python3.6/site-packages (from aiohttp>=3.5.0->mlrun==0.3.3) (1.1.0)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.0 in /conda/lib/python3.6/site-packages (from boto3>=1.9->mlrun==0.3.3) (1.13.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /conda/lib/python3.6/site-packages (from boto3>=1.9->mlrun==0.3.3) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /conda/lib/python3.6/site-packages (from boto3>=1.9->mlrun==0.3.3) (0.2.1)\n",
      "Requirement already satisfied: urllib3>=1.23 in /conda/lib/python3.6/site-packages (from kubernetes>=9.0.0->mlrun==0.3.3) (1.24.2)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /conda/lib/python3.6/site-packages (from kubernetes>=9.0.0->mlrun==0.3.3) (2019.9.11)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /User/.pythonlibs/lib/python3.6/site-packages (from kubernetes>=9.0.0->mlrun==0.3.3) (1.8.1)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /User/.pythonlibs/lib/python3.6/site-packages (from kubernetes>=9.0.0->mlrun==0.3.3) (0.56.0)\n",
      "Requirement already satisfied: requests-oauthlib in /User/.pythonlibs/lib/python3.6/site-packages (from kubernetes>=9.0.0->mlrun==0.3.3) (1.3.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /conda/lib/python3.6/site-packages (from kubernetes>=9.0.0->mlrun==0.3.3) (1.12.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /conda/lib/python3.6/site-packages (from kubernetes>=9.0.0->mlrun==0.3.3) (2.8.0)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /conda/lib/python3.6/site-packages (from kubernetes>=9.0.0->mlrun==0.3.3) (41.4.0)\n",
      "Requirement already satisfied: tornado<6,>=5 in /User/.pythonlibs/lib/python3.6/site-packages (from nuclio-jupyter>=0.7.6->mlrun==0.3.3) (5.1.1)\n",
      "Requirement already satisfied: jupyterlab>=0.35.4 in /conda/lib/python3.6/site-packages (from nuclio-jupyter>=0.7.6->mlrun==0.3.3) (1.0.2)\n",
      "Requirement already satisfied: ipython>=7.2 in /conda/lib/python3.6/site-packages (from nuclio-jupyter>=0.7.6->mlrun==0.3.3) (7.8.0)\n",
      "Requirement already satisfied: nbconvert>=5.4 in /conda/lib/python3.6/site-packages (from nuclio-jupyter>=0.7.6->mlrun==0.3.3) (5.6.0)\n",
      "Requirement already satisfied: notebook>=5.7.2 in /conda/lib/python3.6/site-packages (from nuclio-jupyter>=0.7.6->mlrun==0.3.3) (6.0.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /User/.pythonlibs/lib/python3.6/site-packages (from pandas>=0.23.0->mlrun==0.3.3) (1.17.4)\n",
      "Requirement already satisfied: pytz>=2017.2 in /conda/lib/python3.6/site-packages (from pandas>=0.23.0->mlrun==0.3.3) (2019.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /conda/lib/python3.6/site-packages (from requests>=2.20.1->mlrun==0.3.3) (2.8)\n",
      "Requirement already satisfied: cloudpickle==1.1.1 in /User/.pythonlibs/lib/python3.6/site-packages (from kfp>=0.1.29->mlrun==0.3.3) (1.1.1)\n",
      "Requirement already satisfied: jsonschema>=3.0.1 in /conda/lib/python3.6/site-packages (from kfp>=0.1.29->mlrun==0.3.3) (3.1.1)\n",
      "Requirement already satisfied: PyJWT>=1.6.4 in /User/.pythonlibs/lib/python3.6/site-packages (from kfp>=0.1.29->mlrun==0.3.3) (1.7.1)\n",
      "Requirement already satisfied: requests-toolbelt>=0.8.0 in /User/.pythonlibs/lib/python3.6/site-packages (from kfp>=0.1.29->mlrun==0.3.3) (0.9.1)\n",
      "Requirement already satisfied: Deprecated in /User/.pythonlibs/lib/python3.6/site-packages (from kfp>=0.1.29->mlrun==0.3.3) (1.2.7)\n",
      "Requirement already satisfied: kfp-server-api<=0.1.37,>=0.1.18 in /User/.pythonlibs/lib/python3.6/site-packages (from kfp>=0.1.29->mlrun==0.3.3) (0.1.37)\n",
      "Requirement already satisfied: argo-models==2.2.1a in /User/.pythonlibs/lib/python3.6/site-packages (from kfp>=0.1.29->mlrun==0.3.3) (2.2.1a0)\n",
      "Requirement already satisfied: cryptography>=2.4.2 in /conda/lib/python3.6/site-packages (from kfp>=0.1.29->mlrun==0.3.3) (2.8)\n",
      "Requirement already satisfied: google-cloud-storage>=1.13.0 in /User/.pythonlibs/lib/python3.6/site-packages (from kfp>=0.1.29->mlrun==0.3.3) (1.23.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /conda/lib/python3.6/site-packages (from Jinja2>=2.10.1->Flask>=1.1.1->mlrun==0.3.3) (1.1.1)\n",
      "Requirement already satisfied: smmap2>=2.0.0 in /conda/lib/python3.6/site-packages (from gitdb2>=2.0.0->GitPython>=2.1.0->mlrun==0.3.3) (2.0.5)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /conda/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.0->boto3>=1.9->mlrun==0.3.3) (0.15.2)\n",
      "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /User/.pythonlibs/lib/python3.6/site-packages (from google-auth>=1.0.1->kubernetes>=9.0.0->mlrun==0.3.3) (3.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /User/.pythonlibs/lib/python3.6/site-packages (from google-auth>=1.0.1->kubernetes>=9.0.0->mlrun==0.3.3) (0.2.7)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /User/.pythonlibs/lib/python3.6/site-packages (from google-auth>=1.0.1->kubernetes>=9.0.0->mlrun==0.3.3) (4.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /User/.pythonlibs/lib/python3.6/site-packages (from requests-oauthlib->kubernetes>=9.0.0->mlrun==0.3.3) (3.1.0)\n",
      "Requirement already satisfied: jupyterlab_server~=1.0.0rc0 in /User/.pythonlibs/lib/python3.6/site-packages (from jupyterlab>=0.35.4->nuclio-jupyter>=0.7.6->mlrun==0.3.3) (1.0.0)\n",
      "Requirement already satisfied: pygments in /conda/lib/python3.6/site-packages (from ipython>=7.2->nuclio-jupyter>=0.7.6->mlrun==0.3.3) (2.4.2)\n",
      "Requirement already satisfied: traitlets>=4.2 in /conda/lib/python3.6/site-packages (from ipython>=7.2->nuclio-jupyter>=0.7.6->mlrun==0.3.3) (4.3.3)\n",
      "Requirement already satisfied: jedi>=0.10 in /conda/lib/python3.6/site-packages (from ipython>=7.2->nuclio-jupyter>=0.7.6->mlrun==0.3.3) (0.15.1)\n",
      "Requirement already satisfied: pickleshare in /conda/lib/python3.6/site-packages (from ipython>=7.2->nuclio-jupyter>=0.7.6->mlrun==0.3.3) (0.7.5)\n",
      "Requirement already satisfied: backcall in /conda/lib/python3.6/site-packages (from ipython>=7.2->nuclio-jupyter>=0.7.6->mlrun==0.3.3) (0.1.0)\n",
      "Requirement already satisfied: decorator in /conda/lib/python3.6/site-packages (from ipython>=7.2->nuclio-jupyter>=0.7.6->mlrun==0.3.3) (4.4.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /conda/lib/python3.6/site-packages (from ipython>=7.2->nuclio-jupyter>=0.7.6->mlrun==0.3.3) (2.0.10)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /conda/lib/python3.6/site-packages (from ipython>=7.2->nuclio-jupyter>=0.7.6->mlrun==0.3.3) (4.7.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /conda/lib/python3.6/site-packages (from nbconvert>=5.4->nuclio-jupyter>=0.7.6->mlrun==0.3.3) (0.8.4)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /conda/lib/python3.6/site-packages (from nbconvert>=5.4->nuclio-jupyter>=0.7.6->mlrun==0.3.3) (0.3)\n",
      "Requirement already satisfied: bleach in /conda/lib/python3.6/site-packages (from nbconvert>=5.4->nuclio-jupyter>=0.7.6->mlrun==0.3.3) (3.1.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /conda/lib/python3.6/site-packages (from nbconvert>=5.4->nuclio-jupyter>=0.7.6->mlrun==0.3.3) (1.4.2)\n",
      "Requirement already satisfied: nbformat>=4.4 in /conda/lib/python3.6/site-packages (from nbconvert>=5.4->nuclio-jupyter>=0.7.6->mlrun==0.3.3) (4.4.0)\n",
      "Requirement already satisfied: testpath in /conda/lib/python3.6/site-packages (from nbconvert>=5.4->nuclio-jupyter>=0.7.6->mlrun==0.3.3) (0.4.2)\n",
      "Requirement already satisfied: jupyter-core in /conda/lib/python3.6/site-packages (from nbconvert>=5.4->nuclio-jupyter>=0.7.6->mlrun==0.3.3) (4.6.0)\n",
      "Requirement already satisfied: defusedxml in /conda/lib/python3.6/site-packages (from nbconvert>=5.4->nuclio-jupyter>=0.7.6->mlrun==0.3.3) (0.6.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /conda/lib/python3.6/site-packages (from notebook>=5.7.2->nuclio-jupyter>=0.7.6->mlrun==0.3.3) (18.1.0)\n",
      "Requirement already satisfied: ipykernel in /conda/lib/python3.6/site-packages (from notebook>=5.7.2->nuclio-jupyter>=0.7.6->mlrun==0.3.3) (5.1.2)\n",
      "Requirement already satisfied: prometheus-client in /conda/lib/python3.6/site-packages (from notebook>=5.7.2->nuclio-jupyter>=0.7.6->mlrun==0.3.3) (0.7.1)\n",
      "Requirement already satisfied: Send2Trash in /conda/lib/python3.6/site-packages (from notebook>=5.7.2->nuclio-jupyter>=0.7.6->mlrun==0.3.3) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /conda/lib/python3.6/site-packages (from notebook>=5.7.2->nuclio-jupyter>=0.7.6->mlrun==0.3.3) (0.8.2)\n",
      "Requirement already satisfied: jupyter-client>=5.3.1 in /conda/lib/python3.6/site-packages (from notebook>=5.7.2->nuclio-jupyter>=0.7.6->mlrun==0.3.3) (5.3.4)\n",
      "Requirement already satisfied: ipython-genutils in /conda/lib/python3.6/site-packages (from notebook>=5.7.2->nuclio-jupyter>=0.7.6->mlrun==0.3.3) (0.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /conda/lib/python3.6/site-packages (from jsonschema>=3.0.1->kfp>=0.1.29->mlrun==0.3.3) (0.15.4)\n",
      "Requirement already satisfied: importlib-metadata in /conda/lib/python3.6/site-packages (from jsonschema>=3.0.1->kfp>=0.1.29->mlrun==0.3.3) (0.23)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /User/.pythonlibs/lib/python3.6/site-packages (from Deprecated->kfp>=0.1.29->mlrun==0.3.3) (1.11.2)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /conda/lib/python3.6/site-packages (from cryptography>=2.4.2->kfp>=0.1.29->mlrun==0.3.3) (1.13.0)\n",
      "Requirement already satisfied: google-resumable-media<0.6dev,>=0.5.0 in /User/.pythonlibs/lib/python3.6/site-packages (from google-cloud-storage>=1.13.0->kfp>=0.1.29->mlrun==0.3.3) (0.5.0)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /User/.pythonlibs/lib/python3.6/site-packages (from google-cloud-storage>=1.13.0->kfp>=0.1.29->mlrun==0.3.3) (1.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /User/.pythonlibs/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=9.0.0->mlrun==0.3.3) (0.4.8)\n",
      "Requirement already satisfied: json5 in /conda/lib/python3.6/site-packages (from jupyterlab_server~=1.0.0rc0->jupyterlab>=0.35.4->nuclio-jupyter>=0.7.6->mlrun==0.3.3) (0.8.5)\n",
      "Requirement already satisfied: parso>=0.5.0 in /conda/lib/python3.6/site-packages (from jedi>=0.10->ipython>=7.2->nuclio-jupyter>=0.7.6->mlrun==0.3.3) (0.5.1)\n",
      "Requirement already satisfied: wcwidth in /conda/lib/python3.6/site-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=7.2->nuclio-jupyter>=0.7.6->mlrun==0.3.3) (0.1.7)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /conda/lib/python3.6/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=7.2->nuclio-jupyter>=0.7.6->mlrun==0.3.3) (0.6.0)\n",
      "Requirement already satisfied: webencodings in /conda/lib/python3.6/site-packages (from bleach->nbconvert>=5.4->nuclio-jupyter>=0.7.6->mlrun==0.3.3) (0.5.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /conda/lib/python3.6/site-packages (from importlib-metadata->jsonschema>=3.0.1->kfp>=0.1.29->mlrun==0.3.3) (0.6.0)\n",
      "Requirement already satisfied: pycparser in /conda/lib/python3.6/site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.4.2->kfp>=0.1.29->mlrun==0.3.3) (2.19)\n",
      "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /User/.pythonlibs/lib/python3.6/site-packages (from google-cloud-core<2.0dev,>=1.0.3->google-cloud-storage>=1.13.0->kfp>=0.1.29->mlrun==0.3.3) (1.14.3)\n",
      "Requirement already satisfied: more-itertools in /conda/lib/python3.6/site-packages (from zipp>=0.5->importlib-metadata->jsonschema>=3.0.1->kfp>=0.1.29->mlrun==0.3.3) (7.2.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /conda/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.3->google-cloud-storage>=1.13.0->kfp>=0.1.29->mlrun==0.3.3) (3.10.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /conda/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.3->google-cloud-storage>=1.13.0->kfp>=0.1.29->mlrun==0.3.3) (1.6.0)\n",
      "Building wheels for collected packages: mlrun, sqlalchemy\n",
      "  Running setup.py bdist_wheel for mlrun ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-j28v02iw/wheels/ce/82/2f/a98d204a5dd1b27fa2a685cd11e705f1690d8f7ce2d8c08c9a\n",
      "  Running setup.py bdist_wheel for sqlalchemy ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /igz/.cache/pip/wheels/a3/67/7d/6c41104a1a08ff1a25e260d3edec3ac19203141d1aaa2f0975\n",
      "Successfully built mlrun sqlalchemy\n",
      "Installing collected packages: sqlalchemy, mlrun\n",
      "  Found existing installation: SQLAlchemy 1.2.15\n",
      "    Uninstalling SQLAlchemy-1.2.15:\n",
      "      Successfully uninstalled SQLAlchemy-1.2.15\n",
      "Successfully installed mlrun-0.3.3 sqlalchemy-1.3.11\n"
     ]
    }
   ],
   "source": [
    "# !pip uninstall -y mlrun\n",
    "# !pip install git+https://github.com/mlrun/mlrun.git@development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the KubeFlow pipelines package ```kfp```. For more information see the **[KubeFlow documentation on nuclio](https://www.kubeflow.org/docs/components/misc/nuclio/)** and  **[Kubeflow pipelines and nuclio](https://github.com/kubeflow/pipelines/tree/master/components/nuclio)**. For logging the estimated machine learning models we\"ll use ```joblib```\"s [```dump``` and ```load```](https://joblib.readthedocs.io/en/latest/persistence.html#persistence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: kfp in /User/.pythonlibs/lib/python3.6/site-packages (0.1.37)\n",
      "Requirement already up-to-date: joblib in /User/.pythonlibs/lib/python3.6/site-packages (0.14.1)\n",
      "Requirement already up-to-date: seaborn in /conda/lib/python3.6/site-packages (0.9.0)\n",
      "Requirement already up-to-date: tensorflow==1.14 in /User/.pythonlibs/lib/python3.6/site-packages (1.14.0)\n",
      "Requirement already up-to-date: keras in /User/.pythonlibs/lib/python3.6/site-packages (2.3.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil in /conda/lib/python3.6/site-packages (from kfp) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-storage>=1.13.0 in /User/.pythonlibs/lib/python3.6/site-packages (from kfp) (1.23.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10 in /conda/lib/python3.6/site-packages (from kfp) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: Deprecated in /User/.pythonlibs/lib/python3.6/site-packages (from kfp) (1.2.7)\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle==1.1.1 in /User/.pythonlibs/lib/python3.6/site-packages (from kfp) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: argo-models==2.2.1a in /User/.pythonlibs/lib/python3.6/site-packages (from kfp) (2.2.1a0)\n",
      "Requirement already satisfied, skipping upgrade: tabulate==0.8.3 in /User/.pythonlibs/lib/python3.6/site-packages (from kfp) (0.8.3)\n",
      "Requirement already satisfied, skipping upgrade: PyYAML in /conda/lib/python3.6/site-packages (from kfp) (5.1.2)\n",
      "Requirement already satisfied, skipping upgrade: cryptography>=2.4.2 in /conda/lib/python3.6/site-packages (from kfp) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: PyJWT>=1.6.4 in /User/.pythonlibs/lib/python3.6/site-packages (from kfp) (1.7.1)\n",
      "Requirement already satisfied, skipping upgrade: kubernetes<=9.0.0,>=8.0.0 in /User/.pythonlibs/lib/python3.6/site-packages (from kfp) (9.0.0)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.15 in /conda/lib/python3.6/site-packages (from kfp) (1.24.2)\n",
      "Requirement already satisfied, skipping upgrade: requests-toolbelt>=0.8.0 in /User/.pythonlibs/lib/python3.6/site-packages (from kfp) (0.9.1)\n",
      "Requirement already satisfied, skipping upgrade: kfp-server-api<=0.1.37,>=0.1.18 in /User/.pythonlibs/lib/python3.6/site-packages (from kfp) (0.1.37)\n",
      "Requirement already satisfied, skipping upgrade: jsonschema>=3.0.1 in /conda/lib/python3.6/site-packages (from kfp) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: certifi in /conda/lib/python3.6/site-packages (from kfp) (2019.9.11)\n",
      "Requirement already satisfied, skipping upgrade: google-auth>=1.6.1 in /User/.pythonlibs/lib/python3.6/site-packages (from kfp) (1.8.1)\n",
      "Requirement already satisfied, skipping upgrade: click==7.0 in /conda/lib/python3.6/site-packages (from kfp) (7.0)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib>=1.4.3 in /conda/lib/python3.6/site-packages (from seaborn) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: pandas>=0.15.2 in /User/.pythonlibs/lib/python3.6/site-packages (from seaborn) (0.25.3)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.3 in /User/.pythonlibs/lib/python3.6/site-packages (from seaborn) (1.17.4)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.14.0 in /conda/lib/python3.6/site-packages (from seaborn) (1.3.1)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /User/.pythonlibs/lib/python3.6/site-packages (from tensorflow==1.14) (0.1.8)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /User/.pythonlibs/lib/python3.6/site-packages (from tensorflow==1.14) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /User/.pythonlibs/lib/python3.6/site-packages (from tensorflow==1.14) (0.3.2)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /conda/lib/python3.6/site-packages (from tensorflow==1.14) (0.33.6)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /User/.pythonlibs/lib/python3.6/site-packages (from tensorflow==1.14) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /conda/lib/python3.6/site-packages (from tensorflow==1.14) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /User/.pythonlibs/lib/python3.6/site-packages (from tensorflow==1.14) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /User/.pythonlibs/lib/python3.6/site-packages (from tensorflow==1.14) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /User/.pythonlibs/lib/python3.6/site-packages (from tensorflow==1.14) (1.0.8)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /User/.pythonlibs/lib/python3.6/site-packages (from tensorflow==1.14) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /conda/lib/python3.6/site-packages (from tensorflow==1.14) (3.10.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<1.15.0,>=1.14.0 in /User/.pythonlibs/lib/python3.6/site-packages (from tensorflow==1.14) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /User/.pythonlibs/lib/python3.6/site-packages (from tensorflow==1.14) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /User/.pythonlibs/lib/python3.6/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: google-resumable-media<0.6dev,>=0.5.0 in /User/.pythonlibs/lib/python3.6/site-packages (from google-cloud-storage>=1.13.0->kfp) (0.5.0)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-core<2.0dev,>=1.0.3 in /User/.pythonlibs/lib/python3.6/site-packages (from google-cloud-storage>=1.13.0->kfp) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: cffi!=1.11.3,>=1.8 in /conda/lib/python3.6/site-packages (from cryptography>=2.4.2->kfp) (1.13.0)\n",
      "Requirement already satisfied, skipping upgrade: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /User/.pythonlibs/lib/python3.6/site-packages (from kubernetes<=9.0.0,>=8.0.0->kfp) (0.56.0)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib in /User/.pythonlibs/lib/python3.6/site-packages (from kubernetes<=9.0.0,>=8.0.0->kfp) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in /conda/lib/python3.6/site-packages (from kubernetes<=9.0.0,>=8.0.0->kfp) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=21.0.0 in /conda/lib/python3.6/site-packages (from kubernetes<=9.0.0,>=8.0.0->kfp) (41.4.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata in /conda/lib/python3.6/site-packages (from jsonschema>=3.0.1->kfp) (0.23)\n",
      "Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in /conda/lib/python3.6/site-packages (from jsonschema>=3.0.1->kfp) (0.15.4)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /conda/lib/python3.6/site-packages (from jsonschema>=3.0.1->kfp) (19.3.0)\n",
      "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /User/.pythonlibs/lib/python3.6/site-packages (from google-auth>=1.6.1->kfp) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /User/.pythonlibs/lib/python3.6/site-packages (from google-auth>=1.6.1->kfp) (0.2.7)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<3.2,>=2.0.0 in /User/.pythonlibs/lib/python3.6/site-packages (from google-auth>=1.6.1->kfp) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /conda/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /conda/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /conda/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (2.4.2)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /conda/lib/python3.6/site-packages (from pandas>=0.15.2->seaborn) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /User/.pythonlibs/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /User/.pythonlibs/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: google-api-core<2.0.0dev,>=1.14.0 in /User/.pythonlibs/lib/python3.6/site-packages (from google-cloud-core<2.0dev,>=1.0.3->google-cloud-storage>=1.13.0->kfp) (1.14.3)\n",
      "Requirement already satisfied, skipping upgrade: pycparser in /conda/lib/python3.6/site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.4.2->kfp) (2.19)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /User/.pythonlibs/lib/python3.6/site-packages (from requests-oauthlib->kubernetes<=9.0.0,>=8.0.0->kfp) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /conda/lib/python3.6/site-packages (from requests->kubernetes<=9.0.0,>=8.0.0->kfp) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /conda/lib/python3.6/site-packages (from requests->kubernetes<=9.0.0,>=8.0.0->kfp) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /conda/lib/python3.6/site-packages (from importlib-metadata->jsonschema>=3.0.1->kfp) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /User/.pythonlibs/lib/python3.6/site-packages (from rsa<4.1,>=3.1.4->google-auth>=1.6.1->kfp) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in /conda/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.3->google-cloud-storage>=1.13.0->kfp) (1.6.0)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools in /conda/lib/python3.6/site-packages (from zipp>=0.5->importlib-metadata->jsonschema>=3.0.1->kfp) (7.2.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U kfp joblib seaborn tensorflow==1.14 keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"nuclio-code-section\"></a>\n",
    "# Nuclio code section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nuclio\"s _**ignore**_ notation\n",
    "\n",
    "You\"ll write all the code that gets packaged for execution between the tags ```# nuclio: ignore```, meaning ignore all the code here and above, and ```# nuclio: end-code```, meaning ignore everything after this annotation.  Methods in this code section can be called separately if designed as such (```acquire```, ```split```, ```train```, ```test```), or as you\"ll discover below, they are most often \"chained\" together to form a pipeline where the output of one stage serves as the input to the next. The **[docs](https://github.com/nuclio/nuclio-jupyter#creating-and-debugging-functions-using-nuclio-magic)** also suggest another approach: we can use ```# nuclio: start``` at the first relevant code cell instead of marking all the cells above with ```# nuclio: ignore```.\n",
    "\n",
    "See the **[nuclio-jupyter](https://github.com/nuclio/nuclio-jupyter)** repo for further information on these and many other **[nuclio magic commands](https://github.com/nuclio/nuclio-jupyter#creating-and-debugging-functions-using-nuclio-magic)** that make it easy to transform a Jupyter notebook environment into a platform for developing production-quality, machine learning systems.\n",
    "\n",
    "The ```nuclio-jupyter``` package provides methods for automatically generating and deploying nuclio serverless functions from code, repositories or Jupyter notebooks. **_If you have never run nuclio functions in your notebooks, please uncomment and run the following_**: ```!pip install nuclio-jupyter```\n",
    "\n",
    "The following two lines _**should be in the same cell**_ and mark the start of your mchine learning coding section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"function-dependencies\"></a>\n",
    "### function dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The installs made in the section **[Setup](#Setup)** covered the Jupyter environment within which this notebook runs.  However, we need to ensure that all the dependencies our nuclio function relies upon (such as ```matplotlib```, ```sklearn```, ```lightgbm```), will be available when that code is wrapped up into a nuclio function _**on some presently unknown runtime**_.   Within the nuclio code section we can ensure these dependencies get built into the function with the ```%nuclio cmd``` magic command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nuclio cmd -c pip install -U matplotlib tensorflow==1.14.0 keras sklearn pandas numpy joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We\"ll use a standard base image here, however the build step can be shortened by preparing images with pre-installed packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%nuclio: setting spec.build.baseImage to 'python:3.6-jessie'\n"
     ]
    }
   ],
   "source": [
    "%nuclio config spec.build.baseImage = \"python:3.6-jessie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from io import BytesIO\n",
    "from os import path, makedirs, getenv\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "from typing import IO, AnyStr, TypeVar, Union, List\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (classification_report, \n",
    "                             confusion_matrix, \n",
    "                             accuracy_score,\n",
    "                             f1_score,\n",
    "                             precision_score,\n",
    "                             recall_score)\n",
    "import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "import matplotlib.lines as mlines\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "from pyarrow import Table\n",
    "import v3io_frames as v3f\n",
    "\n",
    "from mlrun.artifacts import ChartArtifact, TableArtifact, PlotArtifact\n",
    "from mlrun.execution import MLClientCtx\n",
    "from mlrun.datastore import DataItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_path = \"/User/projects/paysim/data\"\n",
    "src_path = target_path\n",
    "srcname = \"PS_20174392719_1491204439457_log.csv.zip\"\n",
    "destname = \"paysim.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Components\n",
    "\n",
    "These are the methods that we\"ll be using to compose a pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **tables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_table(ctxtable: MLClientCtx) -> Table:\n",
    "    \"\"\"Get table from context.\n",
    "    \n",
    "    Convenience function to retrieve a table via a blob.\n",
    "    \n",
    "    :param ctxtable: The table saved in the context, \n",
    "            which needs to be deserialized.\n",
    "        \n",
    "    In this demonstration tables are stored in parquet format and passed\n",
    "    between steps as blobs.  We could also pass folder or file names\n",
    "    in the context, which may be faster.\n",
    "    \n",
    "    Returns a pyarrow table.\n",
    "    \"\"\"\n",
    "    blob = BytesIO(ctxtable.get())\n",
    "    return pd.read_parquet(blob, engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_context_table(\n",
    "    context: MLClientCtx,\n",
    "    target: str, \n",
    "    name: str,\n",
    "    table: pd.DataFrame\n",
    ") -> None:\n",
    "    \"\"\"Log a table through the context.\n",
    "    \n",
    "    The table is written as a parquet file, and its target\n",
    "    path is saved in the context.\n",
    "    \n",
    "    :param context: The context.\n",
    "    :param target: Location (folder) of our DataItem.\n",
    "    :param name: Name of the object in the context.\n",
    "    :param table: The object we wish to store.\n",
    "    \"\"\"\n",
    "    context.logger.info(f\"writing {name}\")\n",
    "    pq.write_table(\n",
    "        pa.Table.from_pandas(table),\n",
    "        path.join(target, name))    \n",
    "    context.log_artifact(name, target_path=path.join(target, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_density(\n",
    "    context: MLClientCtx,\n",
    "    artifact_key:str,\n",
    "    time_series: np.ndarray,\n",
    "    title: str = \"Time Series,\n",
    "    xlabel: str = \"time\",\n",
    "    ylabel: str = \"density\",\n",
    "    figsize: Tuple[int, int] = (12,4), # pass a matplotlib plot definition class\n",
    "    color: str = \"#756bb1\" # could be Union some color class...\n",
    ") -> Figure:\n",
    "    \"\"\"Plot density of data points per time interval.\n",
    "\n",
    "    :param context: The context.\n",
    "    :param artifact_key: The plot\"s key in the context.\n",
    "    :param time_series: The time-series whose density we wish to plot.\n",
    "    :param title: Plot title.\n",
    "    :param xlabel: X-axis label.\n",
    "    :param ylabel: Y-axis label.\n",
    "    :param figsize: Matplotlib figsize.\n",
    "    :param fmt: The file image format (png, jpg, ...), and the saved file extension.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.distplot(sdf.step, color=color);\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    context.log_artifact(PlotArtifact(artifact_key, body=plt.gcf()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_validation(\n",
    "    context: MLClientCtx,\n",
    "    train_loss: np.ndarray, \n",
    "    valid_loss: np.ndarray, \n",
    "    title : str = \"training validation results\",\n",
    "    xlabel: str = \"epoch\",\n",
    "    ylabel: str = \"logloss\",\n",
    "    fmt: str = \"png\"):\n",
    "    \"\"\"Plot train and validation loss curves.\n",
    "    \n",
    "    These curves represent the training round losses from the training\n",
    "    and validation sets. The actual type of loss curve depends on the \n",
    "    algorithm and selcted metrics.\n",
    "\n",
    "    :param context: The context.\n",
    "    :param artifact_key: The plot\"s key in the context.\n",
    "    :param train_loss: Vector of loss metric estimates for training set.\n",
    "    :param valid_loss: Predictions given a test sample and an estimated model.\n",
    "    :param title: Plot title.\n",
    "    :param xlabel: X-axis label.\n",
    "    :param ylabel: Y-axis label.\n",
    "    :param fmt: The file image format (png, jpg, ...), and the saved file extension.\n",
    "    \"\"\"\n",
    "    plt.plot(train_loss)\n",
    "    plt.plot(valid_loss)\n",
    "    plt.title(\"\")\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend([\"train\", \"valid\"])\n",
    "    context.log_artifact(PlotArtifact(artifact_key, body=plt.gcf()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(\n",
    "    context: MLClientCtx,\n",
    "    artifact_key: str,\n",
    "    ytest: np.ndarray,\n",
    "    ypred: np.ndarray,\n",
    "    title: str = \"roc curve\",\n",
    "    xlabel: str = \"false positive rate\",\n",
    "    ylabel: str = \"true positive rate\",\n",
    "    fmt: str = \"png\"\n",
    ") -> Figure:\n",
    "    \"\"\"Plot an ROC curve.\n",
    "    \n",
    "    :param context: The context.\n",
    "    :param artifact_key: The plot\"s key in the context.\n",
    "    :param ytest: Ground-truth labels.\n",
    "    :param ypred: Predictions given a test sample and \n",
    "                an estimated model.\n",
    "    :param title: Plot title.\n",
    "    :param xlabel: X-axis label (not tick labels).\n",
    "    :param ylabel: Y-axis label (not tick labels).\n",
    "    :param fmt: The file image format (png, jpg, ...), and \n",
    "                the saved file extension.\n",
    "    \"\"\"\n",
    "    fpr_xg, tpr_xg, _ = roc_curve(ytest, ypred)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")\n",
    "    plt.plot(fpr_xg, tpr_xg, label=\"tf-keras\")\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"best\")\n",
    "    context.log_artifact(PlotArtifact(artifact_key, body=plt.gcf()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(\n",
    "    context: MLClientCtx,\n",
    "    atrifact_key: str,\n",
    "    feature_imps: np.ndarray,\n",
    "    title: str = \"feature importances\",\n",
    "    xlabel: str = \"freq\",\n",
    "    ylabel: str = \"feature\"\n",
    "    fmt: str = \"png\"\n",
    ") -> None:\n",
    "    \"\"\"Generate Feature Importances Chart.\n",
    "    \n",
    "    :param context: The context.\n",
    "    :param artifact_key: The plot\"s key in the context.\n",
    "    :param feature_imps: Feature importances.\n",
    "    :param title: Plot title.\n",
    "    :param xlabel: X-axis label (not tick labels).\n",
    "    :param ylabel: Y-axis label (not tick labels).\n",
    "    :param fmt: The file image format (png, jpg, ...), and \n",
    "                the saved file extension.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.barplot(x=xlabel, y=ylabel, data=feature_imps)\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    fig = plt.gcf()\n",
    "    \n",
    "    context.log_artifact(PlotArtifact(artifact_key, body=plt.gcf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **files**\n",
    "\n",
    "This function would be used to acquire a remote archive (csv, tar, zip,...) and deposit it as a parquet file for performance. No further transformation is undertaken here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arc_to_parquet(\n",
    "    context: MLClientCtx,\n",
    "    archive_url: Union[str, Path, IO[AnyStr]],\n",
    "    header: Union[None, List[str]],\n",
    "    name: str = \"original\",\n",
    "    target_path: str = \"content\",\n",
    "    chunksize: int = 10_000\n",
    ") -> None:\n",
    "    \"\"\"Open a file/object archive and save as a parquet file.\n",
    "    \n",
    "    Args:\n",
    "    :param context: The context.\n",
    "    :param archive_url: Any valid string path consistent with the path variable\n",
    "            of pandas.read_csv. Includes, strings as file paths, as urls, \n",
    "            pathlib.Path objects, etc...\n",
    "    :param header: Column names.\n",
    "    :param target_path: Destination folder of table.\n",
    "    :param chunksize: (default=0). Row size retrieved per iteration. \n",
    "    \"\"\"\n",
    "    makedirs(target_path, exist_ok=True)\n",
    "    context.logger.info(\"verified directories\")\n",
    "   \n",
    "    if not name.endswith(\".parquet\"):\n",
    "        name += \".parquet\"\n",
    "    dest_path = path.join(target_path , name)\n",
    "    \n",
    "    if not path.isfile(dest_path):\n",
    "        context.logger.info(\"destination file does not exist, downloading\")\n",
    "        pqwriter = None\n",
    "        for i, df in enumerate(pd.read_csv(archive_url, chunksize=chunksize, names=header)):\n",
    "            table = pa.Table.from_pandas(df)\n",
    "            if i == 0:\n",
    "                pqwriter = pq.ParquetWriter(dest_path, table.schema)\n",
    "            pqwriter.write_table(table)\n",
    "\n",
    "        if pqwriter:\n",
    "            pqwriter.close()\n",
    "\n",
    "    context.logger.info(f\"saved table to {dest_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **feature engineering**\n",
    "\n",
    "This is a highly specific example, there are many generic feature engineering algos that could be added.\n",
    "\n",
    "In our example, the raw data only contains a ```step``` variable, which represents a time period of 1 hour.  There are 743 unique steps in the data, which is approximately 1 month.  Here we will translate (map) the step values into unique ```DateTime ```s for ingestion into the time series database. We will then save separate ```labels``` and ```features``` objects in the context for use elsewhere: by logging these tables into the context we can expose them as outputs and make them available to another step or even several steps:\n",
    "\n",
    "TODO: we may want to do other stuff here, or wait til training graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_labels(\n",
    "    context: MLClientCtx,\n",
    "    target_path: str = '',\n",
    "    name: str = ''\n",
    "    labels_column = 'labels'\n",
    ") -> None:\n",
    "    \"\"\"Extract features and labels from raw data.\n",
    "    \n",
    "    :param context: The context.\n",
    "    :param target_path: The path for source, labels and features.\n",
    "    :param name: The data source name.\n",
    "    :param labels_column: Column holding ground-truth labels.\n",
    "    \"\"\"\n",
    "    src_filepath = path.join(target_path, name)\n",
    "    if not path.isfile(src_filepath):\n",
    "        msg = 'data has not been downloaded yet or there was a problem'\n",
    "        context.logger.info(msg)\n",
    "        raise Exception(msg)\n",
    "    \n",
    "    # probably a leak\n",
    "    raw.drop('isFlaggedFraud', axis=1, inplace=True)\n",
    "    \n",
    "    # preprocess index by inventing a month and giving each row a unique time\n",
    "    # while still preserving the 'step' category and its distribution.\n",
    "    df = pd.DataFrame(\n",
    "        {\"hours\": pd.date_range(\"2019-01-01\", freq=\"1H\", periods=744)})\n",
    "    # Create the mappings ```dict``` where each unique step is mapped to a start time\n",
    "    time_mappings = {}\n",
    "    for a,b in zip(range(744), df.hours):\n",
    "        time_mappings[a] = b\n",
    "    raw.step = raw.step.map(time_mappings)\n",
    "    steps = []\n",
    "    for (i, g) in enumerate(raw.groupby('step')):\n",
    "        step = g[1].step.values\n",
    "        for r in range(1, step.shape[0]):\n",
    "            step[r] = step[r-1] + np.timedelta64(1,'ms')\n",
    "        steps.append(step)\n",
    "    s = np.concatenate(steps, axis=0)\n",
    "     # does the new vector have the right shape?\n",
    "    assert s.shape == (raw.shape[0],)\n",
    "    raw['step'] = s \n",
    "    # there are as many groups as rows after the change:\n",
    "    assert raw.groupby('step').ngroups == raw.shape[0]\n",
    "\n",
    "    # now set the index, extract labels, and save.\n",
    "    raw.set_index('step', inplace=True)\n",
    "    labels = raw.pop(labels_column)\n",
    "\n",
    "    labels = pd.DataFrame(labels, columns=[\"labels\"])\n",
    "    labels[\"step\"] = s\n",
    "    labels.set_index('step, inplace=True')\n",
    "    \n",
    "    log_context_table(context, target_path, 'features.parquet', raw)\n",
    "    log_context_table(context, target_path, 'labels.parquet', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **tsdb ingress**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import v3io_frames as v3f\n",
    "client = v3f.Client(\"framesd:8081\", container=\"users\")\n",
    "\n",
    "# Relative path to the TSDB table within the parent platform data container\n",
    "tsdb_table = path.join(getenv(\"V3IO_USERNAME\") + \"projects/paysim/tsdb_tbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if path.isdir(tsdb_table):\n",
    "    print(\"found existing table, deleting\")\n",
    "    client.delete(\"tsdb\", tsdb_table)\n",
    "\n",
    "client.create(backend=\"tsdb\", table=tsdb_table, attrs={\"rate\": \"1/s\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeproc = []\n",
    "for g, chunk in features.groupby(1_000):\n",
    "    start = time.time()\n",
    "    client.write(backend=\"tsdb\", table=tsdb_table, dfs=chunk)\n",
    "    timeproc.append(int(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **partitioning**\n",
    "\n",
    "Data partitioning into train, test, and validation sets, cross validation, ... not only  partition the data, also take into account it's distribution, parallelization...\n",
    "\n",
    "TODO: Perhaps use tensorflow dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "load_tag"
    ]
   },
   "outputs": [],
   "source": [
    "def splitter(\n",
    "    context: MLClientCtx,\n",
    "    features: DataItem,\n",
    "    labels: DataItem,\n",
    "    target_path: str = \"\",\n",
    "    test_size: float = 0.1,\n",
    "    train_val_split: float = 0.75,\n",
    "    random_state: int = 1,\n",
    "    sample: int = -1\n",
    ") -> None:\n",
    "    \"\"\"Split raw data into train, validation and test sets.\n",
    "    \n",
    "    The file loaded at this stage is the raw data file that has been\n",
    "    downloaded in a previous step (as a parquet file).  Here it is read\n",
    "    and split into train, validation and test sets. The context is \n",
    "    updated with the target_path.\n",
    "    \n",
    "    context: The `context`.\n",
    "    :param target: Data storage location.\n",
    "    :param src: (default \"original\"). Location of original parquet file.\n",
    "    :param test_size: (defaults=0.1) Set test set size, and leave the\n",
    "            remainder for the second split into train and validation sets.\n",
    "    :param train_val_split: (defaults=0.75) Once the test set has been\n",
    "            removed the training set gets this proportion.\n",
    "    :param random_state: (default 1). Seed used by the scikit-learn random\n",
    "            number generator in the method train_test_split.\n",
    "    :param sample: (default -1, all rows). Selects the first n rows, or\n",
    "            select a sample. Check the balance of resulting sets if\n",
    "            using the random sample option. Use this feature to explore the\n",
    "            system or for debugging.\n",
    "            \n",
    "    Outputs\n",
    "        The following outputs are saved at the target path:\n",
    "        xtrain, ytrain (Tuple[pd.DataFrame, pd.DataFrame]): Training set.\n",
    "        xvalid, yvalid (Tuple[pd.DataFrame, pd.DataFrame]): Validation set.\n",
    "        xtest, ytest (Tuple[pd.DataFrame, pd.DataFrame]): Test set.\n",
    "    \"\"\"\n",
    "    \n",
    "    filepath = path.join(target_path, src)\n",
    "    features = get_context_table(features)\n",
    "    labels = get_context_table(labels\n",
    "    \n",
    "    # split twice to get training, validation and test sets.\n",
    "    context.logger.info(\"splitting into train-valid-test data sets\")\n",
    "    x, xtest, y, ytest = train_test_split(features\n",
    "                                          labels, \n",
    "                                          train_size=1-test_size, \n",
    "                                          test_size=test_size, \n",
    "                                          random_state=random_state)\n",
    "    \n",
    "    xtrain, xvalid, ytrain, yvalid = train_test_split(x, \n",
    "                                                      y, \n",
    "                                                      train_size=train_val_split, \n",
    "                                                      test_size=1-train_val_split,\n",
    "                                                      random_state=random_state)    \n",
    "\n",
    "    # save and log all the intermediate tables\n",
    "    log_context_table(context, target_path, \"xtrain.parquet\", xtrain)\n",
    "    log_context_table(context, target_path, \"xvalid.parquet\", xvalid)\n",
    "    log_context_table(context, target_path, \"xtest.parquet\", xtest)\n",
    "    log_context_table(context, target_path, \"ytrain.parquet\", pd.DataFrame({\"labels\":ytrain}))\n",
    "    log_context_table(context, target_path, \"yvalid.parquet\", pd.DataFrame({\"labels\":yvalid}))\n",
    "    log_context_table(context, target_path, \"ytest.parquet\", pd.DataFrame({\"labels\":ytest}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```train```\n",
    "\n",
    "TODO\n",
    "\n",
    "for more detail on the other parameters available and their default values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(context: MLClientCtx,\n",
    "          xtrain: DataItem,\n",
    "          ytrain: DataItem,\n",
    "          xvalid: DataItem,\n",
    "          yvalid: DataItem,\n",
    "          silent: bool = False,\n",
    "          random_state: int = 1,\n",
    "          model_target: str = \"\",\n",
    "          model_name: str = \"model.defaultname.pickle\",\n",
    "          losses_target = \"\",\n",
    "          losses_name = \"\",\n",
    "          num_leaves: int = 31,\n",
    "          learning_rate: float = 0.1,\n",
    "    ) -> None:\n",
    "    \"\"\"Train and save a LightGBM model.\n",
    "    \n",
    "    :param context: The function\"s context.\n",
    "    :param xtrain: DataItem in context representing 2D array \n",
    "            (obs, features)  of features. \n",
    "    :param ytrain: DataItem in the context representing \n",
    "            ground-truth labels. \n",
    "    :param xvalid: See xtrain, for validation set.\n",
    "    :param yvalid: See ytrain, for validation set.\n",
    "    :param silent : (default False) Show metrics for \n",
    "            training/validation steps.\n",
    "    :param random_state : Random number generator seed.\n",
    "    :param model_target : Destination path for model artifact.\n",
    "    :param model_name : Destination name for model artifact.\n",
    "        \n",
    "    Also included for demonstration are a randomly selected sample\n",
    "    of LightGBM parameters:\n",
    "    :param num_leaves : (Default is 31).  In the LightGBM model\n",
    "            controls complexity.\n",
    "    :param learning_rate : Step size at each iteration, constant.\n",
    "    \"\"\"\n",
    "    context.logger.info(\"read tables\")\n",
    "    xtrain = get_context_table(xtrain)\n",
    "    ytrain = get_context_table(ytrain)\n",
    "    xvalid = get_context_table(xvalid)\n",
    "    yvalid = get_context_table(yvalid)\n",
    "    \n",
    "    context.logger.info(f\"training input {xtrain.shape[0]} rows\")\n",
    "    context.logger.info(\"starting train\")\n",
    "    \n",
    "    <insert model>\n",
    "    \n",
    "    # pickle/serialize the model at target\n",
    "    if not path.isdir(model_target):\n",
    "        makedirs(model_target)\n",
    "    file_path = path.join(model_target, model_name)\n",
    "    joblib.dump(lgb_clf, open(file_path, \"wb\"))\n",
    "    context.log_artifact(\"model_dir\",\n",
    "                         target_path=model_target,\n",
    "                         labels={\"framework\": \"lgbmboost\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```test```\n",
    "\n",
    "In addition to a ```model```, the first step (```load```) created test features and labels we can retrieve and pass on to the ```test``` method.  An ROC plot is built using the test set and make it available for display.\n",
    "\n",
    "TODO: don't expect much change here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(context: MLClientCtx,\n",
    "         model_dir: DataItem, \n",
    "         xtest: DataItem,\n",
    "         ytest: DataItem,\n",
    "         fmt:str = \"png\", \n",
    "         target_path:str = \"\",\n",
    "         model_name: str = \"lightgbm.model.pickle\"):\n",
    "    \"\"\"Load model and predict.\n",
    "    \n",
    "    :param context: The context.\n",
    "    :param model_dir: Contains the model\"s path.\n",
    "    :param xtest: (NxM), N is sample size and M the number of features\n",
    "            of the test set.\n",
    "    :param ytest: 1D (N,1) Array of ground-truth labels,\n",
    "    :param fmt: (Default is \"png\"). The image format.\n",
    "    :param target_path: Unused. \n",
    "        \n",
    "    \"\"\"\n",
    "    print(str(model_dir))\n",
    "    modelpath = path.join(str(model_dir), model_name)\n",
    "    lgbm_model = joblib.load(\n",
    "        open(modelpath, \"rb\"))\n",
    "    \n",
    "    xtest = get_context_table(xtest)\n",
    "    ytest = get_context_table(ytest)\n",
    "    context.logger.info(f\"test input {xtest.shape[0]} rows\")\n",
    "    \n",
    "    ypred = lgbm_model.predict(xtest)\n",
    "    \n",
    "    acc = accuracy_score(ytest, ypred)\n",
    "    \n",
    "    context.logger.info(f\"type: {type(acc)}   value: {acc}\")\n",
    "    context.log_result(\"accuracy\", float(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ```importance```\n",
    "\n",
    "Need to replace this for specific model type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importance(\n",
    "    context: MLClientCtx,\n",
    "    model_dir: DataItem,\n",
    "    xtest: DataItem,\n",
    "    title: str = \"Model Features\",\n",
    "    xlabel:str = \"\",\n",
    "    ylable:str = \"\",\n",
    "    fmt:str = \"png\", \n",
    "    target_path:str = \"\",\n",
    "    model_name: str = \"model.pickle\"\n",
    ")-> None:\n",
    "    \"\"\"Display estimated feature importances.\n",
    "    \n",
    "    :param context: The context.\n",
    "    :param model_dir: Contains the model\"s path.\n",
    "    :param xtest: (NxM), N is sample size and M the number of features\n",
    "            of the test set.\n",
    "    :param title: (Defaults to \"Model Features\"). Plot title.\n",
    "    :param xlabel: Plot x-axis label.\n",
    "    :param ylabel: Plot y-axis label.\n",
    "    :param fmt: (Default is \"png\"). The image format.\n",
    "    :param target_path: Unused.\n",
    "    :param model_name: Name of the model file used to generate the feature\n",
    "        importance vector.\n",
    "    \"\"\"\n",
    "    modelpath = path.join(str(model_dir), model_name)\n",
    "    model = joblib.load(\n",
    "        open(modelpath, \"rb\"))\n",
    "    \n",
    "    xtest = get_context_table(xtest)\n",
    "    \n",
    "    # create a feature importance table with desired labels\n",
    "    zipped = zip(model.feature_importances_, xtest.columns)\n",
    "    \n",
    "    feature_imp = pd.DataFrame(\n",
    "        sorted(zipped), columns=[\"freq\",\"feature\"]\n",
    "    ).sort_values(by=\"freq\", ascending=False)\n",
    "    log_context_table(context, target_path, \"feature-importances-table.csv\", feature_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **end of nuclio function definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"testing\"></a>\n",
    "## Testing locally\n",
    "\n",
    "The function can be run locally and debugged/tested before deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import code_to_function, mount_v3io, new_function, new_model_server, mlconf\n",
    "%env MLRUN_DBPATH=/User/mlrun\n",
    "mlconf.dbpath = \"/User/mlrun\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"image\"></a>\n",
    "### Create a deployment image\n",
    "\n",
    "Once debugged you can create a reusable image, and then deploy it for testing. In the following line we are converting the code block between the ```#nuclio: ignore``` and ```#nuclio: end-code``` to be run as a KubeJob.  Next we build an image named ```mlrun/mlrunlgb:latest```.  _**It is important to ensure that this image has been built at least once, and that you have access to it.**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2019-12-18 20:19:24,195 building image (mlrun/mlrunlgb:latest)\n",
      "FROM python:3.6-jessie\n",
      "WORKDIR /run\n",
      "RUN pip install -U matplotlib seaborn sklearn lightgbm kfp joblib pyarrow\n",
      "RUN pip install mlrun\n",
      "ENV PYTHONPATH /run\n",
      "[mlrun] 2019-12-18 20:19:24,197 using in-cluster config.\n",
      "[mlrun] 2019-12-18 20:19:24,217 Pod mlrun-build-2j6tx created\n",
      "..\n",
      "\u001b[36mINFO\u001b[0m[0000] Resolved base name python:3.6-jessie to python:3.6-jessie \n",
      "\u001b[36mINFO\u001b[0m[0000] Resolved base name python:3.6-jessie to python:3.6-jessie \n",
      "\u001b[36mINFO\u001b[0m[0000] Downloading base image python:3.6-jessie     \n",
      "\u001b[36mINFO\u001b[0m[0000] Error while retrieving image from cache: getting file info: stat /cache/sha256:0318d80cb241983eda20b905d77fa0bfb06e29e5aabf075c7941ea687f1c125a: no such file or directory \n",
      "\u001b[36mINFO\u001b[0m[0000] Downloading base image python:3.6-jessie     \n",
      "\u001b[36mINFO\u001b[0m[0000] Built cross stage deps: map[]                \n",
      "\u001b[36mINFO\u001b[0m[0000] Downloading base image python:3.6-jessie     \n",
      "\u001b[36mINFO\u001b[0m[0001] Error while retrieving image from cache: getting file info: stat /cache/sha256:0318d80cb241983eda20b905d77fa0bfb06e29e5aabf075c7941ea687f1c125a: no such file or directory \n",
      "\u001b[36mINFO\u001b[0m[0001] Downloading base image python:3.6-jessie     \n",
      "\u001b[36mINFO\u001b[0m[0001] Unpacking rootfs as cmd RUN pip install -U matplotlib seaborn sklearn lightgbm kfp joblib pyarrow requires it. \n",
      "\u001b[36mINFO\u001b[0m[0012] Taking snapshot of full filesystem...        \n",
      "\u001b[36mINFO\u001b[0m[0019] WORKDIR /run                                 \n",
      "\u001b[36mINFO\u001b[0m[0019] cmd: workdir                                 \n",
      "\u001b[36mINFO\u001b[0m[0019] Changed working directory to /run            \n",
      "\u001b[36mINFO\u001b[0m[0019] RUN pip install -U matplotlib seaborn sklearn lightgbm kfp joblib pyarrow \n",
      "\u001b[36mINFO\u001b[0m[0019] cmd: /bin/sh                                 \n",
      "\u001b[36mINFO\u001b[0m[0019] args: [-c pip install -U matplotlib seaborn sklearn lightgbm kfp joblib pyarrow] \n",
      "Collecting matplotlib\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/11/06958a2b895a3853206dea1fb2a5b11bf044f626f90745987612af9c8f2c/matplotlib-3.1.2-cp36-cp36m-manylinux1_x86_64.whl (13.1MB)\n",
      "Collecting seaborn\n",
      "  Downloading https://files.pythonhosted.org/packages/a8/76/220ba4420459d9c4c9c9587c6ce607bf56c25b3d3d2de62056efe482dadc/seaborn-0.9.0-py3-none-any.whl (208kB)\n",
      "Collecting sklearn\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Collecting lightgbm\n",
      "  Downloading https://files.pythonhosted.org/packages/0b/9d/ddcb2f43aca194987f1a99e27edf41cf9bc39ea750c3371c2a62698c509a/lightgbm-2.3.1-py2.py3-none-manylinux1_x86_64.whl (1.2MB)\n",
      "Collecting kfp\n",
      "  Downloading https://files.pythonhosted.org/packages/77/5a/c9bc02a4cc2dc91706caff81ea7fc7a64bf27e9c2f3b1de81f4b7440b6b0/kfp-0.1.37.tar.gz (111kB)\n",
      "Collecting joblib\n",
      "  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\n",
      "Collecting pyarrow\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/32/ce1926f05679ea5448fd3b98fbd9419d8c7a65f87d1a12ee5fb9577e3a8e/pyarrow-0.15.1-cp36-cp36m-manylinux2010_x86_64.whl (59.2MB)\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib)\n",
      "  Downloading https://files.pythonhosted.org/packages/c0/0c/fc2e007d9a992d997f04a80125b0f183da7fb554f1de701bbb70a8e7d479/pyparsing-2.4.5-py2.py3-none-any.whl (67kB)\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib)\n",
      "  Downloading https://files.pythonhosted.org/packages/f8/a1/5742b56282449b1c0968197f63eae486eca2c35dcd334bab75ad524e0de1/kiwisolver-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (90kB)\n",
      "Collecting numpy>=1.11 (from matplotlib)\n",
      "  Downloading https://files.pythonhosted.org/packages/d2/ab/43e678759326f728de861edbef34b8e2ad1b1490505f20e0d1f0716c3bf4/numpy-1.17.4-cp36-cp36m-manylinux1_x86_64.whl (20.0MB)\n",
      "Collecting python-dateutil>=2.1 (from matplotlib)\n",
      "  Downloading https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl (227kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Collecting pandas>=0.15.2 (from seaborn)\n",
      "  Downloading https://files.pythonhosted.org/packages/52/3f/f6a428599e0d4497e1595030965b5ba455fd8ade6e977e3c819973c4b41d/pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
      "Collecting scipy>=0.14.0 (from seaborn)\n",
      "  Downloading https://files.pythonhosted.org/packages/f0/7a/579f4659bb488f19f6b458a003b36b86bacaedcb28530f8d25cb153fc5cd/scipy-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (26.1MB)\n",
      "Collecting scikit-learn (from sklearn)\n",
      "  Downloading https://files.pythonhosted.org/packages/2e/d0/860c4f6a7027e00acff373d9f5327f4ae3ed5872234b3cbdd7bcb52e5eff/scikit_learn-0.22-cp36-cp36m-manylinux1_x86_64.whl (7.0MB)\n",
      "Collecting urllib3<1.25,>=1.15 (from kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/01/11/525b02e4acc0c747de8b6ccdab376331597c569c42ea66ab0a1dbd36eca2/urllib3-1.24.3-py2.py3-none-any.whl (118kB)\n",
      "Collecting six>=1.10 (from kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/65/26/32b8464df2a97e6dd1b656ed26b2c194606c16fe163c695a992b36c11cdf/six-1.13.0-py2.py3-none-any.whl\n",
      "Collecting certifi (from kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/b9/63/df50cac98ea0d5b006c55a399c3bf1db9da7b5a24de7890bc9cfd5dd9e99/certifi-2019.11.28-py2.py3-none-any.whl (156kB)\n",
      "Collecting PyYAML (from kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/8d/c9/e5be955a117a1ac548cdd31e37e8fd7b02ce987f9655f5c7563c656d5dcb/PyYAML-5.2.tar.gz (265kB)\n",
      "Collecting google-cloud-storage>=1.13.0 (from kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/87/78/7cf94b3d0961b1a3036ba351c7fdc04170baa73d20fcb41240da214c83fd/google_cloud_storage-1.23.0-py2.py3-none-any.whl (72kB)\n",
      "Collecting kubernetes<=9.0.0,>=8.0.0 (from kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/00/f7/4f196c55f1c2713d3edc8252c4b45326306eef4dc10048f13916fe446e2b/kubernetes-9.0.0-py2.py3-none-any.whl (1.4MB)\n",
      "Collecting PyJWT>=1.6.4 (from kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/87/8b/6a9f14b5f781697e51259d81657e6048fd31a113229cf346880bb7545565/PyJWT-1.7.1-py2.py3-none-any.whl\n",
      "Collecting cryptography>=2.4.2 (from kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/ca/9a/7cece52c46546e214e10811b36b2da52ce1ea7fa203203a629b8dfadad53/cryptography-2.8-cp34-abi3-manylinux2010_x86_64.whl (2.3MB)\n",
      "Collecting google-auth>=1.6.1 (from kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/17/83/3cb31033e1ea0bdb8991b6ef327a5bf4960bd3dd31ff355881bfb0ddf199/google_auth-1.9.0-py2.py3-none-any.whl (75kB)\n",
      "Collecting requests_toolbelt>=0.8.0 (from kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/60/ef/7681134338fc097acef8d9b2f8abe0458e4d87559c689a8c306d0957ece5/requests_toolbelt-0.9.1-py2.py3-none-any.whl (54kB)\n",
      "Collecting cloudpickle==1.1.1 (from kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/24/fb/4f92f8c0f40a0d728b4f3d5ec5ff84353e705d8ff5e3e447620ea98b06bd/cloudpickle-1.1.1-py2.py3-none-any.whl\n",
      "Collecting kfp-server-api<=0.1.37,>=0.1.18 (from kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/c8/ba/4b4f6088fd92e8101f493a2edf6349de951b8c0cf3efac4efa25a997af4a/kfp-server-api-0.1.37.tar.gz\n",
      "Collecting argo-models==2.2.1a (from kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/62/53/a92df7c1c793edf2db99b14e428246e4b49b93499a5c9ed013e0aa2416f6/argo-models-2.2.1a0.tar.gz\n",
      "Collecting jsonschema>=3.0.1 (from kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/c5/8f/51e89ce52a085483359217bc72cdbf6e75ee595d5b1d4b5ade40c7e018b8/jsonschema-3.2.0-py2.py3-none-any.whl (56kB)\n",
      "Collecting tabulate==0.8.3 (from kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/c2/fd/202954b3f0eb896c53b7b6f07390851b1fd2ca84aa95880d7ae4f434c4ac/tabulate-0.8.3.tar.gz (46kB)\n",
      "Collecting click==7.0 (from kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/fa/37/45185cb5abbc30d7257104c434fe0b07e5a195a6847506c074527aa599ec/Click-7.0-py2.py3-none-any.whl (81kB)\n",
      "Collecting Deprecated (from kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/f6/89/62912e01f3cede11edcc0abf81298e3439d9c06c8dce644369380ed13f6d/Deprecated-1.2.7-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib) (41.0.1)\n",
      "Collecting pytz>=2017.2 (from pandas>=0.15.2->seaborn)\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl (509kB)\n",
      "Collecting google-cloud-core<2.0dev,>=1.0.3 (from google-cloud-storage>=1.13.0->kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/93/54/8c5542c0df4c8a92c0b8736ee67abc4daa9ff3734a0119310c125673ac79/google_cloud_core-1.1.0-py2.py3-none-any.whl\n",
      "Collecting google-resumable-media<0.6dev,>=0.5.0 (from google-cloud-storage>=1.13.0->kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/35/9e/f73325d0466ce5bdc36333f1aeb2892ead7b76e79bdb5c8b0493961fa098/google_resumable_media-0.5.0-py2.py3-none-any.whl\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes<=9.0.0,>=8.0.0->kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n",
      "Collecting requests (from kubernetes<=9.0.0,>=8.0.0->kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
      "Collecting requests-oauthlib (from kubernetes<=9.0.0,>=8.0.0->kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Collecting cffi!=1.11.3,>=1.8 (from cryptography>=2.4.2->kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/49/72/0d42f94fe94afa8030350c26e9d787219f3f008ec9bf6b86c66532b29236/cffi-1.13.2-cp36-cp36m-manylinux1_x86_64.whl (397kB)\n",
      "Collecting rsa<4.1,>=3.1.4 (from google-auth>=1.6.1->kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
      "Collecting cachetools<3.2,>=2.0.0 (from google-auth>=1.6.1->kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/2f/a6/30b0a0bef12283e83e58c1d6e7b5aabc7acfc4110df81a4471655d33e704/cachetools-3.1.1-py2.py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.6.1->kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/52/50/bb4cefca37da63a0c52218ba2cb1b1c36110d84dcbae8aa48cd67c5e95c2/pyasn1_modules-0.2.7-py2.py3-none-any.whl (131kB)\n",
      "Collecting importlib-metadata; python_version < \"3.8\" (from jsonschema>=3.0.1->kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/e9/71/1a1e0ed0981bb6a67bce55a210f168126b7ebd2065958673797ea66489ca/importlib_metadata-1.3.0-py2.py3-none-any.whl\n",
      "Collecting pyrsistent>=0.14.0 (from jsonschema>=3.0.1->kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/6f/c1a2e8da80a0029f6b618d7e20e1a6f2a61dd04e2e54225309c2cc4268f7/pyrsistent-0.15.6.tar.gz (107kB)\n",
      "Collecting attrs>=17.4.0 (from jsonschema>=3.0.1->kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/a2/db/4313ab3be961f7a763066401fb77f7748373b6094076ae2bda2806988af6/attrs-19.3.0-py2.py3-none-any.whl\n",
      "Collecting wrapt<2,>=1.10 (from Deprecated->kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/23/84/323c2415280bc4fc880ac5050dddfb3c8062c2552b34c2e512eb4aa68f79/wrapt-1.11.2.tar.gz\n",
      "Collecting google-api-core<2.0.0dev,>=1.14.0 (from google-cloud-core<2.0dev,>=1.0.3->google-cloud-storage>=1.13.0->kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/d0/70/bd363339fc88a1c434655ba03171d46aa2e679e1452cc95a4a8679e76a7a/google_api_core-1.15.0-py2.py3-none-any.whl (69kB)\n",
      "Collecting idna<2.9,>=2.5 (from requests->kubernetes<=9.0.0,>=8.0.0->kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
      "Collecting chardet<3.1.0,>=3.0.2 (from requests->kubernetes<=9.0.0,>=8.0.0->kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib->kubernetes<=9.0.0,>=8.0.0->kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\n",
      "Collecting pycparser (from cffi!=1.11.3,>=1.8->cryptography>=2.4.2->kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/68/9e/49196946aee219aead1290e00d1e7fdeab8567783e83e1b9ab5585e6206a/pycparser-2.19.tar.gz (158kB)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<4.1,>=3.1.4->google-auth>=1.6.1->kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl (77kB)\n",
      "Collecting zipp>=0.5 (from importlib-metadata; python_version < \"3.8\"->jsonschema>=3.0.1->kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/74/3d/1ee25a26411ba0401b43c6376d2316a71addcc72ef8690b101b4ea56d76a/zipp-0.6.0-py2.py3-none-any.whl\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.6.0 (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.3->google-cloud-storage>=1.13.0->kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/eb/ee/e59e74ecac678a14d6abefb9054f0bbcb318a6452a30df3776f133886d7d/googleapis-common-protos-1.6.0.tar.gz\n",
      "Collecting protobuf>=3.4.0 (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.3->google-cloud-storage>=1.13.0->kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/b8/be/438a8b90701aacfd7d741541571a236edbcf46f772caa25fcb27c4937e9e/protobuf-3.11.1-cp36-cp36m-manylinux1_x86_64.whl (1.3MB)\n",
      "Collecting more-itertools (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->jsonschema>=3.0.1->kfp)\n",
      "  Downloading https://files.pythonhosted.org/packages/68/03/0604cec1ea13c9f063dd50f900d1a36160334dd3cfb01fd0e638f61b46ba/more_itertools-8.0.2-py3-none-any.whl (40kB)\n",
      "Building wheels for collected packages: sklearn, kfp, PyYAML, kfp-server-api, argo-models, tabulate, pyrsistent, wrapt, pycparser, googleapis-common-protos\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
      "  Building wheel for kfp (setup.py): started\n",
      "  Building wheel for kfp (setup.py): finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/85/cc/ca/ab6519c6e90dff6cfb38fad88dd95dc734a28c09144327c2cd\n",
      "  Building wheel for PyYAML (setup.py): started\n",
      "  Building wheel for PyYAML (setup.py): finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/54/b7/c7/2ada654ee54483c9329871665aaf4a6056c3ce36f29cf66e67\n",
      "  Building wheel for kfp-server-api (setup.py): started\n",
      "  Building wheel for kfp-server-api (setup.py): finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/88/91/06/c5356e8438626814069fdc8ddd620ad984b1dd389ec44c8f07\n",
      "  Building wheel for argo-models (setup.py): started\n",
      "  Building wheel for argo-models (setup.py): finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/bd/5b/6b/20cdc06ddb10caa3a86f5804eb9a90122ae8de0bcf19a468d8\n",
      "  Building wheel for tabulate (setup.py): started\n",
      "  Building wheel for tabulate (setup.py): finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/2b/67/89/414471314a2d15de625d184d8be6d38a03ae1e983dbda91e84\n",
      "  Building wheel for pyrsistent (setup.py): started\n",
      "  Building wheel for pyrsistent (setup.py): finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/83/89/d3/1712b9c33c9b9c0911b188a86aeff2a9a05e113f986cf79d92\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/d7/de/2e/efa132238792efb6459a96e85916ef8597fcb3d2ae51590dfd\n",
      "  Building wheel for pycparser (setup.py): started\n",
      "  Building wheel for pycparser (setup.py): finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/f2/9a/90/de94f8556265ddc9d9c8b271b0f63e57b26fb1d67a45564511\n",
      "  Building wheel for googleapis-common-protos (setup.py): started\n",
      "  Building wheel for googleapis-common-protos (setup.py): finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/9e/3d/a2/1bec8bb7db80ab3216dbc33092bb7ccd0debfb8ba42b5668d5\n",
      "Successfully built sklearn kfp PyYAML kfp-server-api argo-models tabulate pyrsistent wrapt pycparser googleapis-common-protos\n",
      "Installing collected packages: pyparsing, kiwisolver, numpy, six, python-dateutil, cycler, matplotlib, pytz, pandas, scipy, seaborn, joblib, scikit-learn, sklearn, lightgbm, urllib3, certifi, PyYAML, protobuf, googleapis-common-protos, idna, chardet, requests, pyasn1, rsa, cachetools, pyasn1-modules, google-auth, google-api-core, google-cloud-core, google-resumable-media, google-cloud-storage, websocket-client, oauthlib, requests-oauthlib, kubernetes, PyJWT, pycparser, cffi, cryptography, requests-toolbelt, cloudpickle, kfp-server-api, argo-models, more-itertools, zipp, importlib-metadata, pyrsistent, attrs, jsonschema, tabulate, click, wrapt, Deprecated, kfp, pyarrow\n",
      "Successfully installed Deprecated-1.2.7 PyJWT-1.7.1 PyYAML-5.2 argo-models-2.2.1a0 attrs-19.3.0 cachetools-3.1.1 certifi-2019.11.28 cffi-1.13.2 chardet-3.0.4 click-7.0 cloudpickle-1.1.1 cryptography-2.8 cycler-0.10.0 google-api-core-1.15.0 google-auth-1.9.0 google-cloud-core-1.1.0 google-cloud-storage-1.23.0 google-resumable-media-0.5.0 googleapis-common-protos-1.6.0 idna-2.8 importlib-metadata-1.3.0 joblib-0.14.1 jsonschema-3.2.0 kfp-0.1.37 kfp-server-api-0.1.37 kiwisolver-1.1.0 kubernetes-9.0.0 lightgbm-2.3.1 matplotlib-3.1.2 more-itertools-8.0.2 numpy-1.17.4 oauthlib-3.1.0 pandas-0.25.3 protobuf-3.11.1 pyarrow-0.15.1 pyasn1-0.4.8 pyasn1-modules-0.2.7 pycparser-2.19 pyparsing-2.4.5 pyrsistent-0.15.6 python-dateutil-2.8.1 pytz-2019.3 requests-2.22.0 requests-oauthlib-1.3.0 requests-toolbelt-0.9.1 rsa-4.0 scikit-learn-0.22 scipy-1.4.0 seaborn-0.9.0 six-1.13.0 sklearn-0.0 tabulate-0.8.3 urllib3-1.24.3 websocket-client-0.56.0 wrapt-1.11.2 zipp-0.6.0\n",
      "WARNING: You are using pip version 19.1.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "\u001b[36mINFO\u001b[0m[0058] Taking snapshot of full filesystem...        \n",
      "\u001b[36mINFO\u001b[0m[0078] RUN pip install mlrun                        \n",
      "\u001b[36mINFO\u001b[0m[0078] cmd: /bin/sh                                 \n",
      "\u001b[36mINFO\u001b[0m[0078] args: [-c pip install mlrun]                 \n",
      "Collecting mlrun\n",
      "  Downloading https://files.pythonhosted.org/packages/94/79/a5dc7e8f5efe46d869c6e4a4a361fe29ac72371303412a45960ed9c4ed08/mlrun-0.3.3-py3-none-any.whl (91kB)\n",
      "Requirement already satisfied: kubernetes>=9.0.0 in /usr/local/lib/python3.6/site-packages (from mlrun) (9.0.0)\n",
      "Requirement already satisfied: requests>=2.20.1 in /usr/local/lib/python3.6/site-packages (from mlrun) (2.22.0)\n",
      "Collecting aiohttp>=3.5.0 (from mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/7c/39/7eb5f98d24904e0f6d3edb505d4aa60e3ef83c0a58d6fe18244a51757247/aiohttp-3.6.2-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/site-packages (from mlrun) (7.0)\n",
      "Collecting gunicorn==19.9.0 (from mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/8c/da/b8dd8deb741bff556db53902d4706774c8e1e67265f69528c14c003644e6/gunicorn-19.9.0-py2.py3-none-any.whl (112kB)\n",
      "Collecting nest-asyncio>=1.0.0 (from mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/52/01/55100e0dda328f2181b719bddc5af0a24487de81038747d676d5be7ef879/nest_asyncio-1.2.1-py3-none-any.whl\n",
      "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.6/site-packages (from mlrun) (0.25.3)\n",
      "Requirement already satisfied: tabulate>=0.8.0 in /usr/local/lib/python3.6/site-packages (from mlrun) (0.8.3)\n",
      "Collecting Flask>=1.1.1 (from mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/9b/93/628509b8d5dc749656a9641f4caf13540e2cdec85276964ff8f43bbb1d3b/Flask-1.1.1-py2.py3-none-any.whl (94kB)\n",
      "Collecting nuclio-jupyter>=0.7.6 (from mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/c4/91/1d3523fcc90eefa51719f14777ea3886f2579c764f957b3c2c23361e255f/nuclio_jupyter-0.7.6-py3-none-any.whl (45kB)\n",
      "Collecting GitPython>=2.1.0 (from mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/20/8c/4543981439d23c4ff65b2e62dddd767ebc84a8e664a9b67e840d1e2730d3/GitPython-3.0.5-py3-none-any.whl (455kB)\n",
      "Requirement already satisfied: pyyaml>=5.1.0 in /usr/local/lib/python3.6/site-packages (from mlrun) (5.2)\n",
      "Collecting nuclio-sdk>=0.0.3 (from mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/82/23/ce0d7bba26365c7e94cae1ccfa41323d43490c622fa8f1207aabfc4e5a3d/nuclio_sdk-0.0.5-py2.py3-none-any.whl\n",
      "Collecting boto3>=1.9 (from mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/56/7c/4961f6a8756face3a8b021848829c9431a3d367ee1ec77e0d9ba611c65cf/boto3-1.10.42-py2.py3-none-any.whl (128kB)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.6/site-packages (from kubernetes>=9.0.0->mlrun) (2019.11.28)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.6/site-packages (from kubernetes>=9.0.0->mlrun) (1.3.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.6/site-packages (from kubernetes>=9.0.0->mlrun) (0.56.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/site-packages (from kubernetes>=9.0.0->mlrun) (1.13.0)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.6/site-packages (from kubernetes>=9.0.0->mlrun) (41.0.1)\n",
      "Requirement already satisfied: urllib3>=1.23 in /usr/local/lib/python3.6/site-packages (from kubernetes>=9.0.0->mlrun) (1.24.3)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.6/site-packages (from kubernetes>=9.0.0->mlrun) (1.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.6/site-packages (from kubernetes>=9.0.0->mlrun) (2.8.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/site-packages (from requests>=2.20.1->mlrun) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/site-packages (from requests>=2.20.1->mlrun) (3.0.4)\n",
      "Collecting typing-extensions>=3.6.5; python_version < \"3.7\" (from aiohttp>=3.5.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/03/92/705fe8aca27678e01bbdd7738173b8e7df0088a2202c80352f664630d638/typing_extensions-3.7.4.1-py3-none-any.whl\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/site-packages (from aiohttp>=3.5.0->mlrun) (19.3.0)\n",
      "Collecting multidict<5.0,>=4.5 (from aiohttp>=3.5.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/db/58/1ccd67520bb6ac5be71ec73d0f12d603f863335af9234e5b7600dcd4c5d0/multidict-4.7.1-cp36-cp36m-manylinux1_x86_64.whl (114kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp>=3.5.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/95/8f/0209fc5d975f839344c33c822ff2f7ef80f6b1e984673a5a68f960bfa583/yarl-1.4.2-cp36-cp36m-manylinux1_x86_64.whl (252kB)\n",
      "Collecting async-timeout<4.0,>=3.0 (from aiohttp>=3.5.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
      "Collecting idna-ssl>=1.0; python_version < \"3.7\" (from aiohttp>=3.5.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/46/03/07c4894aae38b0de52b52586b24bf189bb83e4ddabfe2e2c8f2419eec6f4/idna-ssl-1.1.0.tar.gz\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/site-packages (from pandas>=0.23.0->mlrun) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/site-packages (from pandas>=0.23.0->mlrun) (1.17.4)\n",
      "Collecting Jinja2>=2.10.1 (from Flask>=1.1.1->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/65/e0/eb35e762802015cab1ccee04e8a277b03f1d8e53da3ec3106882ec42558b/Jinja2-2.10.3-py2.py3-none-any.whl (125kB)\n",
      "Collecting Werkzeug>=0.15 (from Flask>=1.1.1->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/ce/42/3aeda98f96e85fd26180534d36570e4d18108d62ae36f87694b476b83d6f/Werkzeug-0.16.0-py2.py3-none-any.whl (327kB)\n",
      "Collecting itsdangerous>=0.24 (from Flask>=1.1.1->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/76/ae/44b03b253d6fade317f32c24d100b3b35c2239807046a4c953c7b89fa49e/itsdangerous-1.1.0-py2.py3-none-any.whl\n",
      "Collecting notebook>=5.7.2 (from nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/f5/69/d2ffaf7efc20ce47469187e3a41e6e03e17b45de5a6559f4e7ab3eace5e1/notebook-6.0.2-py3-none-any.whl (9.7MB)\n",
      "Collecting jupyterlab>=0.35.4 (from nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/35/9a/6e81535ed42ad01ec2a5e8f9e0419108f60fab36e48dc1168fa5e0576a81/jupyterlab-1.2.4-py2.py3-none-any.whl (6.4MB)\n",
      "Collecting nbconvert>=5.4 (from nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/79/6c/05a569e9f703d18aacb89b7ad6075b404e8a4afde2c26b73ca77bb644b14/nbconvert-5.6.1-py2.py3-none-any.whl (455kB)\n",
      "Collecting ipython>=7.2 (from nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/c4/c0/dc2e62d068f0f63910a3ab565a7fbbe1a20946b23f0945525826d9bbc98f/ipython-7.10.2-py3-none-any.whl (778kB)\n",
      "Collecting tornado<6,>=5 (from nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/e6/78/6e7b5af12c12bdf38ca9bfe863fcaf53dc10430a312d0324e76c1e5ca426/tornado-5.1.1.tar.gz (516kB)\n",
      "Collecting gitdb2>=2.0.0 (from GitPython>=2.1.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/03/6c/99296f89bad2ef85626e1df9f677acbee8885bb043ad82ad3ed4746d2325/gitdb2-2.0.6-py2.py3-none-any.whl (63kB)\n",
      "Collecting botocore<1.14.0,>=1.13.42 (from boto3>=1.9->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/49/f3/4280c60c707bbcab43e5d91fd74c1573455b68f483c3e2221eee18cc1a85/botocore-1.13.42-py2.py3-none-any.whl (5.8MB)\n",
      "Collecting s3transfer<0.3.0,>=0.2.0 (from boto3>=1.9->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/16/8a/1fc3dba0c4923c2a76e1ff0d52b305c44606da63f718d14d3231e21c51b0/s3transfer-0.2.1-py2.py3-none-any.whl (70kB)\n",
      "Collecting jmespath<1.0.0,>=0.7.1 (from boto3>=1.9->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/83/94/7179c3832a6d45b266ddb2aac329e101367fbdb11f425f13771d27f225bb/jmespath-0.9.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/site-packages (from requests-oauthlib->kubernetes>=9.0.0->mlrun) (3.1.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/site-packages (from google-auth>=1.0.1->kubernetes>=9.0.0->mlrun) (4.0)\n",
      "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/site-packages (from google-auth>=1.0.1->kubernetes>=9.0.0->mlrun) (3.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/site-packages (from google-auth>=1.0.1->kubernetes>=9.0.0->mlrun) (0.2.7)\n",
      "Collecting MarkupSafe>=0.23 (from Jinja2>=2.10.1->Flask>=1.1.1->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/b2/5f/23e0023be6bb885d00ffbefad2942bc51a620328ee910f64abe5a8d18dd1/MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting ipython-genutils (from notebook>=5.7.2->nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/fa/bc/9bd3b5c2b4774d5f33b2d544f1460be9df7df2fe42f352135381c347c69a/ipython_genutils-0.2.0-py2.py3-none-any.whl\n",
      "Collecting traitlets>=4.2.1 (from notebook>=5.7.2->nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/ca/ab/872a23e29cec3cf2594af7e857f18b687ad21039c1f9b922fac5b9b142d5/traitlets-4.3.3-py2.py3-none-any.whl (75kB)\n",
      "Collecting jupyter-core>=4.6.0 (from notebook>=5.7.2->nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/fb/82/86437f661875e30682e99d04c13ba6c216f86f5f6ca6ef212d3ee8b6ca11/jupyter_core-4.6.1-py2.py3-none-any.whl (82kB)\n",
      "Collecting prometheus-client (from notebook>=5.7.2->nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/b3/23/41a5a24b502d35a4ad50a5bb7202a5e1d9a0364d0c12f56db3dbf7aca76d/prometheus_client-0.7.1.tar.gz\n",
      "Collecting jupyter-client>=5.3.4 (from notebook>=5.7.2->nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/13/81/fe0eee1bcf949851a120254b1f530ae1e01bdde2d3ab9710c6ff81525061/jupyter_client-5.3.4-py2.py3-none-any.whl (92kB)\n",
      "Collecting Send2Trash (from notebook>=5.7.2->nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/49/46/c3dc27481d1cc57b9385aff41c474ceb7714f7935b1247194adae45db714/Send2Trash-1.5.0-py3-none-any.whl\n",
      "Collecting terminado>=0.8.1 (from notebook>=5.7.2->nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/ff/96/1d9a2c23990aea8f8e0b5c3b6627d03196a73771a17a2d9860bbe9823ab6/terminado-0.8.3-py2.py3-none-any.whl\n",
      "Collecting ipykernel (from notebook>=5.7.2->nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/e1/92/8fec943b5b81078399f969f00557804d884c96fcd0bc296e81a2ed4fd270/ipykernel-5.1.3-py3-none-any.whl (116kB)\n",
      "Collecting pyzmq>=17 (from notebook>=5.7.2->nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/94/07/cee3d328a2e13f9de1c2b62cced7a389b61ac81424f2e377f3dc9d668282/pyzmq-18.1.1-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "Collecting nbformat (from notebook>=5.7.2->nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/da/27/9a654d2b6cc1eaa517d1c5a4405166c7f6d72f04f6e7eea41855fe808a46/nbformat-4.4.0-py2.py3-none-any.whl (155kB)\n",
      "Collecting jupyterlab-server~=1.0.0 (from jupyterlab>=0.35.4->nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/78/98/5b87b9d38176bd98f23b58a8fb730e5124618d68571a011abbd38ad4a842/jupyterlab_server-1.0.6-py3-none-any.whl\n",
      "Collecting bleach (from nbconvert>=5.4->nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/ab/05/27e1466475e816d3001efb6e0a85a819be17411420494a1e602c36f8299d/bleach-3.1.0-py2.py3-none-any.whl (157kB)\n",
      "Collecting testpath (from nbconvert>=5.4->nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/1b/9e/1a170feaa54f22aeb5a5d16c9015e82234275a3c8ab630b552493f9cb8a9/testpath-0.4.4-py2.py3-none-any.whl (163kB)\n",
      "Collecting mistune<2,>=0.8.1 (from nbconvert>=5.4->nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/09/ec/4b43dae793655b7d8a25f76119624350b4d65eb663459eb9603d7f1f0345/mistune-0.8.4-py2.py3-none-any.whl\n",
      "Collecting pandocfilters>=1.4.1 (from nbconvert>=5.4->nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/4c/ea/236e2584af67bb6df960832731a6e5325fd4441de001767da328c33368ce/pandocfilters-1.4.2.tar.gz\n",
      "Collecting defusedxml (from nbconvert>=5.4->nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/06/74/9b387472866358ebc08732de3da6dc48e44b0aacd2ddaa5cb85ab7e986a2/defusedxml-0.6.0-py2.py3-none-any.whl\n",
      "Collecting entrypoints>=0.2.2 (from nbconvert>=5.4->nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/ac/c6/44694103f8c221443ee6b0041f69e2740d89a25641e62fb4f2ee568f2f9c/entrypoints-0.3-py2.py3-none-any.whl\n",
      "Collecting pygments (from nbconvert>=5.4->nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/be/39/32da3184734730c0e4d3fa3b2b5872104668ad6dc1b5a73d8e477e5fe967/Pygments-2.5.2-py2.py3-none-any.whl (896kB)\n",
      "Collecting decorator (from ipython>=7.2->nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/8f/b7/f329cfdc75f3d28d12c65980e4469e2fa373f1953f5df6e370e84ea2e875/decorator-4.4.1-py2.py3-none-any.whl\n",
      "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 (from ipython>=7.2->nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/7f/1f/e145dd467dc9b0e6f1e64232c03119498dfec497e383f1e8be9f83eaa97e/prompt_toolkit-3.0.2-py3-none-any.whl (344kB)\n",
      "Collecting pexpect; sys_platform != \"win32\" (from ipython>=7.2->nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/0e/3e/377007e3f36ec42f1b84ec322ee12141a9e10d808312e5738f52f80a232c/pexpect-4.7.0-py2.py3-none-any.whl (58kB)\n",
      "Collecting jedi>=0.10 (from ipython>=7.2->nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/55/54/da994f359e4e7da4776a200e76dbc85ba5fc319eefc22e33d55296d95a1d/jedi-0.15.1-py2.py3-none-any.whl (1.0MB)\n",
      "Collecting pickleshare (from ipython>=7.2->nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/9a/41/220f49aaea88bc6fa6cba8d05ecf24676326156c23b991e80b3f2fc24c77/pickleshare-0.7.5-py2.py3-none-any.whl\n",
      "Collecting backcall (from ipython>=7.2->nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/84/71/c8ca4f5bb1e08401b916c68003acf0a0655df935d74d93bf3f3364b310e0/backcall-0.1.0.tar.gz\n",
      "Collecting smmap2>=2.0.0 (from gitdb2>=2.0.0->GitPython>=2.1.0->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/55/d2/866d45e3a121ee15a1dc013824d58072fd5c7799c9c34d01378eb262ca8f/smmap2-2.0.5-py2.py3-none-any.whl\n",
      "Collecting docutils<0.16,>=0.10 (from botocore<1.14.0,>=1.13.42->boto3>=1.9->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/22/cd/a6aa959dca619918ccb55023b4cb151949c64d4d5d55b3f4ffd7eee0c6e8/docutils-0.15.2-py3-none-any.whl (547kB)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/site-packages (from rsa<4.1,>=3.1.4->google-auth>=1.0.1->kubernetes>=9.0.0->mlrun) (0.4.8)\n",
      "Collecting ptyprocess; os_name != \"nt\" (from terminado>=0.8.1->notebook>=5.7.2->nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/29/605c2cc68a9992d18dada28206eeada56ea4bd07a239669da41674648b6f/ptyprocess-0.6.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/site-packages (from nbformat->notebook>=5.7.2->nuclio-jupyter>=0.7.6->mlrun) (3.2.0)\n",
      "Collecting json5 (from jupyterlab-server~=1.0.0->jupyterlab>=0.35.4->nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/30/44/062543d4a6718f99d82e5ecf9140dbdee8a03122f2c34fbd0b0609891707/json5-0.8.5-py2.py3-none-any.whl\n",
      "Collecting webencodings (from bleach->nbconvert>=5.4->nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl\n",
      "Collecting wcwidth (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.2->nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/7e/9f/526a6947247599b084ee5232e4f9190a38f398d7300d866af3ab571a5bfe/wcwidth-0.1.7-py2.py3-none-any.whl\n",
      "Collecting parso>=0.5.0 (from jedi>=0.10->ipython>=7.2->nuclio-jupyter>=0.7.6->mlrun)\n",
      "  Downloading https://files.pythonhosted.org/packages/9b/b0/90353a5ece0987279837835224dead0c424833a224195683e188d384e06b/parso-0.5.2-py2.py3-none-any.whl (99kB)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook>=5.7.2->nuclio-jupyter>=0.7.6->mlrun) (0.15.6)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook>=5.7.2->nuclio-jupyter>=0.7.6->mlrun) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema!=2.5.0,>=2.4->nbformat->notebook>=5.7.2->nuclio-jupyter>=0.7.6->mlrun) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.6/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->jsonschema!=2.5.0,>=2.4->nbformat->notebook>=5.7.2->nuclio-jupyter>=0.7.6->mlrun) (8.0.2)\n",
      "Building wheels for collected packages: idna-ssl, tornado, prometheus-client, pandocfilters, backcall\n",
      "  Building wheel for idna-ssl (setup.py): started\n",
      "  Building wheel for idna-ssl (setup.py): finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/d3/00/b3/32d613e19e08a739751dd6bf998cfed277728f8b2127ad4eb7\n",
      "  Building wheel for tornado (setup.py): started\n",
      "  Building wheel for tornado (setup.py): finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/6d/e1/ce/f4ee2fa420cc6b940123c64992b81047816d0a9fad6b879325\n",
      "  Building wheel for prometheus-client (setup.py): started\n",
      "  Building wheel for prometheus-client (setup.py): finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/1c/54/34/fd47cd9b308826cc4292b54449c1899a30251ef3b506bc91ea\n",
      "  Building wheel for pandocfilters (setup.py): started\n",
      "  Building wheel for pandocfilters (setup.py): finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/39/01/56/f1b08a6275acc59e846fa4c1e1b65dbc1919f20157d9e66c20\n",
      "  Building wheel for backcall (setup.py): started\n",
      "  Building wheel for backcall (setup.py): finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/98/b0/dd/29e28ff615af3dda4c67cab719dd51357597eabff926976b45\n",
      "Successfully built idna-ssl tornado prometheus-client pandocfilters backcall\n",
      "ERROR: botocore 1.13.42 has requirement python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\", but you'll have python-dateutil 2.8.1 which is incompatible.\n",
      "Installing collected packages: typing-extensions, multidict, yarl, async-timeout, idna-ssl, aiohttp, gunicorn, nest-asyncio, MarkupSafe, Jinja2, Werkzeug, itsdangerous, Flask, ipython-genutils, decorator, traitlets, jupyter-core, prometheus-client, tornado, pyzmq, jupyter-client, Send2Trash, ptyprocess, terminado, wcwidth, prompt-toolkit, pexpect, parso, jedi, pickleshare, backcall, pygments, ipython, ipykernel, nbformat, webencodings, bleach, testpath, mistune, pandocfilters, defusedxml, entrypoints, nbconvert, notebook, json5, jupyterlab-server, jupyterlab, nuclio-sdk, jmespath, docutils, botocore, s3transfer, boto3, nuclio-jupyter, smmap2, gitdb2, GitPython, mlrun\n",
      "Successfully installed Flask-1.1.1 GitPython-3.0.5 Jinja2-2.10.3 MarkupSafe-1.1.1 Send2Trash-1.5.0 Werkzeug-0.16.0 aiohttp-3.6.2 async-timeout-3.0.1 backcall-0.1.0 bleach-3.1.0 boto3-1.10.42 botocore-1.13.42 decorator-4.4.1 defusedxml-0.6.0 docutils-0.15.2 entrypoints-0.3 gitdb2-2.0.6 gunicorn-19.9.0 idna-ssl-1.1.0 ipykernel-5.1.3 ipython-7.10.2 ipython-genutils-0.2.0 itsdangerous-1.1.0 jedi-0.15.1 jmespath-0.9.4 json5-0.8.5 jupyter-client-5.3.4 jupyter-core-4.6.1 jupyterlab-1.2.4 jupyterlab-server-1.0.6 mistune-0.8.4 mlrun-0.3.3 multidict-4.7.1 nbconvert-5.6.1 nbformat-4.4.0 nest-asyncio-1.2.1 notebook-6.0.2 nuclio-jupyter-0.7.6 nuclio-sdk-0.0.5 pandocfilters-1.4.2 parso-0.5.2 pexpect-4.7.0 pickleshare-0.7.5 prometheus-client-0.7.1 prompt-toolkit-3.0.2 ptyprocess-0.6.0 pygments-2.5.2 pyzmq-18.1.1 s3transfer-0.2.1 smmap2-2.0.5 terminado-0.8.3 testpath-0.4.4 tornado-5.1.1 traitlets-4.3.3 typing-extensions-3.7.4.1 wcwidth-0.1.7 webencodings-0.5.1 yarl-1.4.2\n",
      "WARNING: You are using pip version 19.1.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "\u001b[36mINFO\u001b[0m[0096] Taking snapshot of full filesystem...        \n",
      "\u001b[36mINFO\u001b[0m[0106] ENV PYTHONPATH /run                          \n",
      "[mlrun] 2019-12-18 20:21:37,689 build completed with succeeded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.kubejob.KubejobRuntime at 0x7fabc92761d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_job = code_to_function(runtime=\"job\").apply(mount_v3io())\n",
    "\n",
    "lgbm_job.build(image=\"mlrun/mlrunlgb:latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While debugging, and _**after you have run**_ ```build``` **_at least once**_, you can comment out the last cell so that the build process isn\"t started needlessly.  The code can be injected into the job using the following line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgbm_job.with_code()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pipeline\"></a>\n",
    "### Create a KubeFlow Pipeline from our functions\n",
    "\n",
    "Our pipeline will consist of two instead of three steps, ```load``` and ```train```.  We\"ll drop the ```test```\n",
    "here since at the end of this deployment we can test the system with API requests.\n",
    "\n",
    "For complete details on KubeFlow Pipelines please refer to the following docs:\n",
    "1. **[KubeFlow pipelines](https://www.kubeflow.org/docs/pipelines/)**.\n",
    "2. **[kfp.dsl Python package](https://kubeflow-pipelines.readthedocs.io/en/latest/source/kfp.dsl.html#module-kfp.dsl)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note, the model server file name in the ```new_model_server``` function call below should identical in every respect to the name of the model server notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import dsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"TF-Keras Classifier Training Pipeline - Paysim\",\n",
    "    description=\"Shows how to use mlrun/kfp.\"\n",
    ")\n",
    "def tfkeras_pipeline(\n",
    "   learning_rate = [0.1, 0.3]\n",
    "):\n",
    "\n",
    "    <insert pipeline>\n",
    "\n",
    "    # define a nuclio-serving function, generated from a notebook file\n",
    "    srvfn = new_model_server(\n",
    "        \"paysim-serving\", \n",
    "        model_class=\"TFKerasClassifier\", \n",
    "        filename=\"model-server.ipynb\")\n",
    "    \n",
    "    # deploy the model serving function with inputs from the training stage\n",
    "    deploy = srvfn.with_v3io(\"User\", \"~/\").deploy_step(project=\"refactor-demos\", \n",
    "                                                       models={\"tfkeras_v1_joblib\": train_step.outputs[\"model_dir\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"compile the pipeline\"></a>\n",
    "### compile the pipeline\n",
    "\n",
    "We can compile our KubeFlow pipeline and produce a yaml description of the pipeline worflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/User/.pythonlibs/lib/python3.6/site-packages/kfp/components/_data_passing.py:133: UserWarning: Missing type name was inferred as \"JsonArray\" based on the value \"[0.1, 0.3]\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n",
      "/User/.pythonlibs/lib/python3.6/site-packages/kfp/components/_data_passing.py:133: UserWarning: Missing type name was inferred as \"JsonArray\" based on the value \"[31, 32]\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n"
     ]
    }
   ],
   "source": [
    "makedirs(\"/User/projects/tfkeras/yaml\", exist_ok=True)\n",
    "kfp.compiler.Compiler().compile(lgbm_pipeline, \"/User/projects/tfkeras/yaml/mlrunpipe.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client(namespace=\"default-tenant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the following line will run the pipeline as a job::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"/pipeline/#/experiments/details/2462ffc0-1a91-41e9-aae6-dc58aed013f3\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"/pipeline/#/runs/details/fdc66ab5-c036-44b8-9ebf-3858814c973a\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arguments = {\n",
    "    \"learning_rate\": [ 0.1, 0.3]\n",
    "}\n",
    "\n",
    "run_result = client.create_run_from_pipeline_func(\n",
    "    tfkeras_pipeline, \n",
    "    arguments, \n",
    "    run_name=\"tfkeras 1\",\n",
    "    experiment_name=\"tfkeras_tsdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
