{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Server**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "## **steps**\n",
    "**[notebook installs](#installs)**<br>\n",
    "**[nuclio code section](#nuclio)**<br>\n",
    "    - [inference server](#server)<br>\n",
    "**[deploy](#deploy)**<br>\n",
    "**[test deployment](#test)**<br>\n",
    "**[test saved model object](#testingoutside)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"installs\"></a>\n",
    "_______________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **notebook installs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the packages we'll need to run this notebook, please install them once:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "    !pip install -U kfserving==0.2.0 tensorflow==2.0.0b1 keras pandas \n",
    "    !pip install -U kubernetes==9.0.0\n",
    "    !pip install -U azure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    !pip install -U git+https://github.com/yjb-ds/functions-demo.git\n",
    "    !pip install -U git+https://github.com/mlrun/mlrun.git@development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"nuclio\"></a>\n",
    "_______________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **nuclio code section**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have never run nuclio functions in your notebooks, please uncomment and run the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "    !pip install nuclio-jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the following packages so they are available to the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nuclio cmd -c\n",
    "pip install kfserving==0.2.0\n",
    "pip install  numpy==1.16.4 tensorflow==2.0.0b1 pandas==0.25.3\n",
    "pip install -U azure joblib\n",
    "pip install -U git+https://github.com/yjb-ds/functions-demo.git\n",
    "pip install -U git+https://github.com/mlrun/mlrun.git@development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "import kfserving\n",
    "import numpy as np\n",
    "import joblib\n",
    "from typing import List\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from functions.models import FeaturesEngineer, classifier_gen\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "class MyKerasClassifier(kfserving.KFModel):\n",
    "    def __init__(self,\n",
    "                 name: str,\n",
    "                 model_dir: str,\n",
    "                 classifier: Sequential = None):\n",
    "        \"\"\"TFKerasClassifier\n",
    "        \n",
    "        KubeFlow serving model wrapper.\n",
    "        \n",
    "        :param name:            model name\n",
    "        :param model_dir: path of stored model\n",
    "        :param classifier:      class type of classifier model\n",
    "        \n",
    "        \"\"\"\n",
    "        super().__init__(name)\n",
    "        self.name = name\n",
    "        self.model_dir = model_dir\n",
    "        if classifier:\n",
    "            self.ready = True\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"Load model from KubeFlow storage.\n",
    "        \"\"\"\n",
    "        ffg = FeaturesEngineer()\n",
    "\n",
    "        # scaler\n",
    "        ss = StandardScaler()\n",
    "        ss.__dict__ = joblib.load(f\"{self.model_dir}/scaler.pickle\")\n",
    "\n",
    "        # keras model\n",
    "        ksm = classifier_gen()\n",
    "        ksm.load_weights(f\"{self.model_dir}/weights.h5\")\n",
    "\n",
    "        pipe = make_pipeline(ffg, ss, ksm)\n",
    "\n",
    "        self.classifier = pipe\n",
    "\n",
    "    def predict(self, body: List) -> List:\n",
    "        \"\"\"Generate model predictions from sample.\n",
    "        \n",
    "        :param body: A list of observations, each of which is an 1-dimensional feature vector.\n",
    "            \n",
    "        Returns model predictions as a `List`, one for each row in the `body` input `List`.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            feats = np.asarray(body['instances'])\n",
    "            result: np.ndarray = self.classifier.predict(feats)\n",
    "            return result.tolist()\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Failed to predict {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"deploy\"></a>\n",
    "_______________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **deploy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import new_model_server, mount_v3io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_PATH = \"/User/mlrun/simdata\"\n",
    "MODEL_NAME = \"tfkeras_serving_v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = new_model_server(MODEL_NAME, \n",
    "                      models={\"tfkeras_joblib_v2\": TARGET_PATH}, \n",
    "                      model_class=\"MyKerasClassifier\").apply(mount_v3io())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-01-01 19:11:09,207 deploy started\n",
      "[nuclio] 2020-01-01 19:11:09,276 (info) Building processor image\n",
      "[nuclio] 2020-01-01 19:11:13,315 (info) Build complete\n",
      "[nuclio] 2020-01-01 19:11:20,468 done updating tfkeras-serving-v2, function address: 3.137.70.243:30350\n"
     ]
    }
   ],
   "source": [
    "#fn.verbose=True\n",
    "addr = fn.deploy(project=\"refactoring-demos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"testingoutside\"></a>\n",
    "### **testing our model outside the server**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 20)\n",
      "here\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.2862316370010376],\n",
       " [0.784155011177063],\n",
       " [0.9990143775939941],\n",
       " [0.03990083932876587],\n",
       " [0.8113516569137573],\n",
       " [0.9939308166503906],\n",
       " [0.09553894400596619],\n",
       " [0.7177563905715942],\n",
       " [0.9736238121986389],\n",
       " [0.9602663516998291],\n",
       " [0.8558810949325562],\n",
       " [0.01912662386894226],\n",
       " [0.7599364519119263],\n",
       " [0.08660963177680969],\n",
       " [0.9928114414215088],\n",
       " [0.028684556484222412],\n",
       " [0.010364711284637451],\n",
       " [0.014988690614700317],\n",
       " [0.01085364818572998],\n",
       " [0.14172640442848206],\n",
       " [0.8549386262893677],\n",
       " [0.10782825946807861],\n",
       " [0.8087799549102783],\n",
       " [0.02626052498817444],\n",
       " [0.020626991987228394],\n",
       " [0.8675011396408081],\n",
       " [0.034037262201309204],\n",
       " [0.7863306999206543],\n",
       " [0.04210638999938965],\n",
       " [0.9636402130126953],\n",
       " [0.014158755540847778],\n",
       " [0.014376461505889893],\n",
       " [0.9978076219558716],\n",
       " [0.9215453267097473],\n",
       " [0.008119255304336548],\n",
       " [0.002589106559753418],\n",
       " [0.6740338206291199],\n",
       " [0.9730592370033264],\n",
       " [0.0462263822555542],\n",
       " [0.8003339171409607],\n",
       " [0.5833727121353149],\n",
       " [0.24764549732208252],\n",
       " [0.9933905601501465],\n",
       " [0.05620896816253662],\n",
       " [0.07263728976249695],\n",
       " [0.20948874950408936],\n",
       " [0.986519992351532],\n",
       " [0.20227909088134766],\n",
       " [0.9937171339988708],\n",
       " [0.3655363917350769],\n",
       " [0.30331718921661377],\n",
       " [0.30177661776542664],\n",
       " [0.061366528272628784],\n",
       " [0.6973257660865784],\n",
       " [0.4193618893623352],\n",
       " [0.4541124701499939],\n",
       " [0.02056989073753357],\n",
       " [0.23425650596618652],\n",
       " [0.11364632844924927],\n",
       " [0.11191102862358093],\n",
       " [0.08471336960792542],\n",
       " [0.01929721236228943],\n",
       " [0.043101489543914795],\n",
       " [0.05524146556854248],\n",
       " [0.3894377648830414],\n",
       " [0.9331333041191101],\n",
       " [0.06179109215736389],\n",
       " [0.04347437620162964],\n",
       " [0.9949864149093628],\n",
       " [0.5433110594749451],\n",
       " [0.021424025297164917],\n",
       " [0.00074005126953125],\n",
       " [0.009887009859085083],\n",
       " [0.8886376619338989],\n",
       " [0.024483084678649902],\n",
       " [0.441640704870224],\n",
       " [0.17243635654449463],\n",
       " [0.23651105165481567],\n",
       " [0.9965943098068237],\n",
       " [0.9907300472259521],\n",
       " [0.8626164197921753],\n",
       " [0.9999370574951172],\n",
       " [0.9868645668029785],\n",
       " [0.021090924739837646],\n",
       " [0.5314356684684753],\n",
       " [0.08253803849220276],\n",
       " [0.04511818289756775],\n",
       " [0.6620529890060425],\n",
       " [0.157316654920578],\n",
       " [0.9922676086425781],\n",
       " [0.034567803144454956],\n",
       " [0.8589380383491516],\n",
       " [0.9848911762237549],\n",
       " [0.19190162420272827],\n",
       " [0.9965924024581909],\n",
       " [0.9553931951522827],\n",
       " [0.024482160806655884],\n",
       " [0.15468232333660126],\n",
       " [0.0015264410758391023],\n",
       " [0.3733447790145874]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics  import accuracy_score\n",
    "\n",
    "# create and load\n",
    "model = MyKerasClassifier('anyname', model_dir=TARGET_PATH)\n",
    "model.load()\n",
    "\n",
    "model.predict({'instances' : features.values.tolist()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import pandas as pd\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab some data - balanced dataset\n",
    "features = pd.read_csv(\"x_test_50.csv\")\n",
    "labels = pd.read_csv(\"y_test_50.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = {'instances' : features.values.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Exception caught in handler \"Failed to predict not enough values to unpack (expected 2, got 1)\": Traceback (most recent call last):\\n  File \"/opt/nuclio/model_server.py\", line 60, in predict\\n    result: np.ndarray = self.classifier.predict(feats)\\n  File \"/usr/local/lib/python3.6/site-packages/sklearn/utils/metaestimators.py\", line 116, in <lambda>\\n    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)\\n  File \"/usr/local/lib/python3.6/site-packages/sklearn/pipeline.py\", line 417, in predict\\n    Xt = transform.transform(Xt)\\n  File \"/usr/local/lib/python3.6/site-packages/functions/models.py\", line 119, in transform\\n    n, f = x.shape\\nValueError: not enough values to unpack (expected 2, got 1)\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/opt/nuclio/_nuclio_wrapper.py\", line 176, in serve_requests\\n    entrypoint_output = self._entrypoint(self._context, event)\\n  File \"/opt/nuclio/model_server.py\", line 71, in handler\\n    return context.mlrun_handler(context, event)\\n  File \"/usr/local/lib/python3.6/site-packages/mlrun/runtimes/serving.py\", line 67, in nuclio_serving_handler\\n    return route(context, model_name, event)\\n  File \"/usr/local/lib/python3.6/site-packages/mlrun/runtimes/serving.py\", line 135, in post\\n    response = model.predict(request)\\n  File \"/opt/nuclio/model_server.py\", line 63, in predict\\n    raise Exception(f\"Failed to predict {e}\")\\nException: Failed to predict not enough values to unpack (expected 2, got 1)\\n'\n"
     ]
    }
   ],
   "source": [
    "resp = requests.put(addr + \"/tfkeras_joblib_v2/predict\", json=event)\n",
    "print(resp.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
