{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Server**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "## **steps**\n",
    "**[notebook installs](#installs)**<br>\n",
    "**[nuclio code section](#nuclio)**<br>\n",
    "    - [inference server](#server)<br>\n",
    "**[deploy](#deploy)**<br>\n",
    "**[test deployment](#test)**<br>\n",
    "**[test saved model object](#testingoutside)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"installs\"></a>\n",
    "_______________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **notebook installs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the packages we'll need to run this notebook, please install them once:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "    !pip install -U kfserving==0.2.0 tensorflow==2.0.0b1 keras pandas \n",
    "    !pip install -U kubernetes==9.0.0\n",
    "    !pip install -U azure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "    !pip uninstall -y mlrun\n",
    "    !pip install mlrun\n",
    "    !pip install -U git+https://github.com/yjb-ds/functions-demo.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"nuclio\"></a>\n",
    "_______________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **nuclio code section**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have never run nuclio functions in your notebooks, please uncomment and run the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "    !pip install nuclio-jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the following packages so they are available to the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nuclio cmd -c\n",
    "pip install kfserving==0.2.0\n",
    "pip install numpy==1.16.4 \n",
    "pip install tensorflow==2.0.0b1\n",
    "pip install pandas==0.25.3\n",
    "pip install azure\n",
    "pip install joblib\n",
    "pip install mlrun\n",
    "pip install git+https://github.com/yjb-ds/functions-demo.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "import kfserving\n",
    "import numpy as np\n",
    "import joblib\n",
    "from typing import List\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from functions.models import (model_gen,\n",
    "                              FeaturesEngineer,\n",
    "                              pipeline_load)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "\n",
    "class MyKerasClassifier(kfserving.KFModel):\n",
    "    def __init__(self,\n",
    "                 name: str,\n",
    "                 model_dir: str,\n",
    "                 classifier: Sequential = None):\n",
    "        \"\"\"TFKerasClassifier\n",
    "        \n",
    "        Server model wrapper.\n",
    "        \n",
    "        :param name:            model name\n",
    "        :param model_dir:       path of stored model\n",
    "        :param classifier:      class type of classifier model\n",
    "        \n",
    "        \"\"\"\n",
    "        super().__init__(name)\n",
    "        self.name = name\n",
    "        self.model_dir = model_dir\n",
    "        if classifier:\n",
    "            self.ready = True\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"Load model from storage.\n",
    "        \n",
    "        Note that loading to load a model we specify only a folder. Our custom\n",
    "        loader takes care of the details.\n",
    "        \"\"\"\n",
    "        self.classifier = pipeline_load(self.model_dir)\n",
    "    \n",
    "    def predict(self, body):\n",
    "        \"\"\"Generate model predictions from sample.\n",
    "        \n",
    "        :param body: A list of observations, each of which is an 1-dimensional feature vector.\n",
    "            \n",
    "        Returns model predictions as a `List`, one for each row in the `body` input `List`.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            feats = np.asarray(body['instances'])\n",
    "            result: np.ndarray = self.classifier.predict(feats)\n",
    "            return result.tolist()\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Failed to predict {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"deploy\"></a>\n",
    "_______________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **deploy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import new_model_server, mount_v3io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_PATH = \"/User/mlrun/simdata\"\n",
    "MODEL_NAME = \"tfkeras\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = new_model_server(MODEL_NAME, \n",
    "                      models={\"tfkeras_joblib\": TARGET_PATH}, \n",
    "                      model_class=\"MyKerasClassifier\").apply(mount_v3io())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While debugging your project code, you may want to set the following flag to `True` in order to ensure that all the layers in your image get rebuilt and your changes included:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.spec.no_cache=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the following cell, you can start watching the function's deployment by selecting **Projects** in the Iguazio platform UI, and clicking on the project name, and selecting the correct function and version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-01-04 16:13:35,635 deploy started\n",
      "[nuclio] 2020-01-04 16:13:35,662 project name not found created new (mlrun-demos)\n"
     ]
    }
   ],
   "source": [
    "addr = fn.deploy(project=(\"mlrun-demos\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"deploy\"></a>\n",
    "_______________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### grab 2 rows of data - balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"x_test_50.csv\").iloc[:2,:]\n",
    "labels = pd.read_csv(\"y_test_50.csv\").iloc[:2,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create an event and wrap it in json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = {\"instances\" : features.values.tolist()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the notebook is restarted for some reason, however the function has already been deployed, simply uncomment the following cell and paste in the original endpoint here.  You can \n",
    "retrieve the function's enpoint address from the platform ui under **Projects**. Look for\n",
    "the project name you gave to the deployment of interest, in our case **mlrun-demos**.\n",
    "Click on the function in the project, copy the 'Invocation URL' and paste here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# addr = \"3.137.70.243:31811\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.21110223233699799], [0.676588237285614]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = requests.post(addr + \"/tfkeras_joblib/predict\", json=event)\n",
    "\n",
    "json.loads(resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
