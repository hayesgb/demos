{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Server**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "## **steps**\n",
    "**[notebook installs](#installs)**<br>\n",
    "**[nuclio code section](#nuclio)**<br>\n",
    "    - [inference server](#server)<br>\n",
    "**[deploy](#deploy)**<br>\n",
    "**[test deployment](#test)**<br>\n",
    "**[test saved model object](#infderence)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"installs\"></a>\n",
    "_______________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **notebook installs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the packages we'll need to run this notebook, please install them once:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "    !pip install -U kfserving==0.2.0 tensorflow==2.0.0b1 keras pandas \n",
    "    !pip install -U kubernetes==9.0.0\n",
    "    !pip install -U git+https://github.com/mlrun/mlrun.git@development\n",
    "    !pip install -U azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     !pip install -U git+https://github.com/yjb-ds/functions-demo.git\n",
    "#     !pip install -U git+https://github.com/mlrun/mlrun.git@development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"nuclio\"></a>\n",
    "_______________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **nuclio code section**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have never run nuclio functions in your notebooks, please uncomment and run the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    !pip install nuclio-jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the following packages available to the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nuclio cmd -c\n",
    "pip install -U kfserving==0.2.0 azure numpy tensorflow==2.0.0b1 keras joblib\n",
    "pip install -U git+https://github.com/mlrun/mlrun.git@development\n",
    "pip install -U git+https://github.com/yjb-ds/functions-demo.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"server\"></a>\n",
    "### _**inference server**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfserving\n",
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "from typing import List\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from functions.models import FeaturesEngineer, classifier_gen\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline, Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_PATH = '/User/mlrun/simdata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFKerasClassifier(kfserving.KFModel):\n",
    "    def __init__(self,\n",
    "                 name: str,\n",
    "                 model_dir: str,\n",
    "                 classifier: Sequential = None):\n",
    "        \"\"\"TFKerasClassifier\n",
    "        \n",
    "        KubeFlow serving model wrapper.\n",
    "        \n",
    "        :param name:            model name\n",
    "        :param model_dir: path of stored model\n",
    "        :param classifier:      class type of classifier model\n",
    "        \n",
    "        \"\"\"\n",
    "        super().__init__(name)\n",
    "        self.name = name\n",
    "        self.model_dir = model_dir\n",
    "        if classifier:\n",
    "            self.ready = True\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"Load model from KubeFlow storage.\n",
    "        \"\"\"\n",
    "        ffg = FeaturesGenerator()\n",
    "\n",
    "        # scaler\n",
    "        ss = StandardScaler()\n",
    "        ss.__dict__ = joblib.load(f'{model_dir}/scaler.pickle')\n",
    "\n",
    "        # keras model\n",
    "        ksm = classifier_gen()\n",
    "        ksm.load_weights(f'{model_dir}/weights.h5')\n",
    "\n",
    "        pipe = make_pipeline(ffg, ss, ksm)\n",
    "\n",
    "#       pipe = os.path.join(\n",
    "#             kfserving.Storage.download(self.model_dir), 'scaler.pickle')\n",
    "\n",
    "        self.classifier = pipe\n",
    "\n",
    "    def predict(self, body: List) -> List:\n",
    "        \"\"\"Generate model predictions from sample.\n",
    "        \n",
    "        :param body: A list of observations, each of which is an 1-dimensional feature vector.\n",
    "            \n",
    "        Returns model predictions as a `List`, one for each row in the `body` input `List`.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            feats = np.asarray(body)\n",
    "            result: np.ndarray = self.classifier.predict(feats)\n",
    "            return result.tolist()\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Failed to predict {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"deploy\"></a>\n",
    "_______________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **deploy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import new_model_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.function.RemoteRuntime at 0x7f8ffc14ccc0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn = new_model_server(\"tfkeras-serving\", \n",
    "                      models={\"tfkeras_joblib\": TARGET_PATH}, \n",
    "                      model_class=\"TFKerasClassifier\")\n",
    "fn.with_v3io(\"User\",\"~/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2019-12-30 11:15:11,489 deploy started\n",
      "[nuclio] 2019-12-30 11:15:12,566 (info) Building processor image\n",
      "[nuclio] 2019-12-30 11:18:28,454 (info) Build complete\n",
      "[nuclio] 2019-12-30 11:18:38,628 (info) Function deploy complete\n",
      "[nuclio] 2019-12-30 11:18:38,633 done creating tfkeras-serving, function address: 3.136.3.102:30972\n"
     ]
    }
   ],
   "source": [
    "#fn.verbose=True\n",
    "addr = fn.deploy(project=\"refactor-demos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a d=\"test\"></a>\n",
    "_______________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **test deployment endpoint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import pandas as pd\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab some data from the test set\n",
    "xtest = pq.read_table(\"/User/projects/paysim/data/xtest.parquet\").to_pandas()\n",
    "ytest = pq.read_table(\"/User/projects/paysim/data/ytest.parquet\").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seldon protocol event\n",
    "event_seldon = {\n",
    "    \"data\" : {\n",
    "        \"ndarray\": features.values.tolist()\n",
    "    }\n",
    "}\n",
    "csel = str(event_seldon).replace(\"\\\"\", \"\\\"\").replace(\"\\n\", \"\").replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.put(addr + \"/predict/tfkeras_joblib\", data=csel)\n",
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"inference-test\"></a>\n",
    "_______________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **test saved model object**\n",
    "\n",
    "Here we run a test outside of mlrun and the context: grab the estimated model file created on the **[kubeflow pipeline](kubeflow-pipeline.ipynb)**, load, and run a test matrix through it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "model_file = f\"/User/projects/paysim/{CLASSIFIER_FILE}\"\n",
    "tfkeras_model = joblib.load(open(model_file, \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _**test one row**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testvals = [1.86888885,1.57777536,-0.39419246,2.05800271,-0.75799805,1.57381201,1.4090718,1.26302791,1.08653808,1.22390795,0.46826237,0.78775787,0.,0.84368491,0.33878541,-0.4717221,2.54822445,0.38823441,-0.57677436,1.70674813,0.,0.8656919,0.87541604,0.98195601,2.04881859,1.63834357,1.42886198,1.33937621]\n",
    "testvals = np.asarray(testvals).reshape(-1,1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model.predict(testvals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _**test matrix**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlrun clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
