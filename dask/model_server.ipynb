{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy a Serverless Model Server with Nuclio-KFServing\n",
    "  --------------------------------------------------------------------\n",
    "\n",
    "The following notebook demonstrates how to deploy **any pickled model** using **[nuclio](https://github.com/nuclio/nuclio)** + **[KFServing](https://github.com/kubeflow/kfserving)** (a.k.a <b>Nuclio-serving</b>)\n",
    "\n",
    "#### **notebook how-to's**\n",
    "* Write and test model serving (KFServing) class in a notebook.\n",
    "* Deploy the model server as a Nuclio-serving function.\n",
    "* Invoke and test the serving function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "#### **steps**\n",
    "**[define a new function and its dependencies](#define-function)**<br>\n",
    "**[test the model serving class locally](#test-locally)**<br>\n",
    "**[deploy our serving class using as a serverless function](#deploy)**<br>\n",
    "**[test our model server using HTTP request](#test-model-server)**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "# if the nuclio-jupyter package is not installed run !pip install nuclio-jupyter\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='define-function'></a>\n",
    "### **define a new function and its dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%nuclio: setting kind to 'nuclio:serving'\n",
      "%nuclio: setting 'MODEL_CLASS' environment variable\n"
     ]
    }
   ],
   "source": [
    "%nuclio config kind=\"nuclio:serving\"\n",
    "%nuclio env MODEL_CLASS=ClassifierModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nuclio cmd -c\n",
    "pip install -U -q kfserving\n",
    "pip install -U -q azure\n",
    "pip install -U -q mlrun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%nuclio config spec.build.image = \"yjbds/mlrun-serving:dev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfserving\n",
    "import os\n",
    "import numpy as np\n",
    "from cloudpickle import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_PATH = '/User/repos/demos/dask/artifacts'\n",
    "MODEL_FILE = 'lgbm-model.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierModel(kfserving.KFModel):\n",
    "    def __init__(self, name: str, model_dir: str, model = None):\n",
    "        super().__init__(name)\n",
    "        self.name = name\n",
    "        self.model_dir = model_dir\n",
    "        if not model is None:\n",
    "            self.classifier = model\n",
    "            self.ready = True\n",
    "\n",
    "    def load(self):\n",
    "        model_file = os.path.join(\n",
    "            kfserving.Storage.download(self.model_dir), MODEL_FILE)\n",
    "        self.classifier = load(open(model_file, 'rb'))\n",
    "        self.ready = True\n",
    "\n",
    "    def predict(self, body):\n",
    "        try:\n",
    "            feats = np.asarray(body['instances'])\n",
    "            result: np.ndarray = self.classifier.predict(feats)\n",
    "            return result.tolist()\n",
    "        except Exception as e:\n",
    "            raise Exception(\"Failed to predict %s\" % e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following end-code annotation tells ```nuclio``` to stop parsing the notebook from this cell. _**Please do not remove this cell**_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='test-locally'></a>\n",
    "### **test the model serving class locally**\n",
    "The class above can be tested locally. Just instantiate the class, `.load()` will load the model to a local dir.\n",
    "\n",
    "> **Verify there is a `model.bst` file in the model_dir path (generated by the training notebook)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/User/.pythonlibs/jupyter-1/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.preprocessing.label module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/User/.pythonlibs/jupyter-1/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "model = load(open(TARGET_PATH + '/' + MODEL_FILE, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.1,\n",
       "               local_listen_port=12400,\n",
       "               machines='10.233.64.59:12400,10.233.64.53:12401,10.233.64.54:12402,10.233.64.56:12403,10.233.64.58:12404,10.233.64.55:12405,10.233.64.57:12406,10.233.64.52:12407',\n",
       "               max_depth=3, min_child_samples=20, min_child_weight=0.001,\n",
       "               min_split_gain=0.0, n_estimators=3, n_jobs=-1, num_leaves=31,\n",
       "               num_machines=8, num_threads=1, objective=None, random_state=1,\n",
       "               reg_alpha=0.0, reg_lambda=0.0, silent=False, subsample=1.0,\n",
       "               subsample_for_bin=200000, subsample_freq=0, time_out=120,\n",
       "               tree_learner='data')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 200216 14:56:42 storage:35] Copying contents of /User/repos/demos/dask/artifacts to local\n"
     ]
    }
   ],
   "source": [
    "my_server = ClassifierModel('classifier', model_dir=TARGET_PATH, model = model)\n",
    "my_server.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _data_\n",
    "Make some classification data using scikit learn's `make_classification`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dask\n",
    "# import pandas as pd\n",
    "# import dask.dataframe as dd\n",
    "# import pyarrow.parquet as pq\n",
    "# import pyarrow\n",
    "\n",
    "# xtest = pd.read_parquet('/User/repos/demos/dask/artifacts/test_set')\n",
    "\n",
    "# xtest.head()\n",
    "\n",
    "# xtest.pop('index')\n",
    "\n",
    "# ytest = xtest.pop('ArrDelay')\n",
    "\n",
    "# event = {\"instances\": xtest.values.tolist()}\n",
    "\n",
    "# ytest\n",
    "\n",
    "# my_server.predict(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='deploy'></a>\n",
    "### **deploy our serving class using as a serverless function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlrun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = mlrun.new_model_server('generic', \n",
    "                            models={'classifier_gen': TARGET_PATH}, \n",
    "                            model_class='ClassifierModel').apply(mlrun.mount_v3io())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-02-16 14:56:59,377 deploy started\n",
      "[nuclio] 2020-02-16 15:01:00,676 (info) Build complete\n",
      "[nuclio] 2020-02-16 15:02:02,692 (error) Failed to deploy. Details:\n",
      "[E 200216 15:01:42 logger:106] Caught unhandled exception while initializing\n",
      "[E 200216 15:01:42 logger:106] Caught unhandled exception while initializing\n",
      "[E 200216 15:01:42 logger:106] Caught unhandled exception while initializing\n",
      "[E 200216 15:01:42 logger:106] Caught unhandled exception while initializing\n",
      "[E 200216 15:01:42 logger:106] Caught unhandled exception while initializing\n",
      "[E 200216 15:01:42 logger:106] Caught unhandled exception while initializing\n",
      "Caught unhandled exception while initializing [err=\"'str' object has no attribute 'name'\" || traceback=\"Traceback (most recent call last):\n",
      "  File \"/opt/nuclio/_nuclio_wrapper.py\", line 272, in run_wrapper\n",
      "    args.trigger_name)\n",
      "  File \"/opt/nuclio/_nuclio_wrapper.py\", line 56, in __init__\n",
      "    self._context = nuclio_sdk.Context(self._logger, self._platform, worker_id, trigger_name)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/nuclio_sdk/context.py\", line 31, in __init__\n",
      "    self.trigger_name = self.trigger.name\n",
      "AttributeError: 'str' object has no attribute 'name'\n",
      "\"]\n",
      "Failed to read from connection [name=\"processor.http.w6.python.logger\" || err=\"EOF\"]\n",
      "Caught unhandled exception while initializing [err=\"'str' object has no attribute 'name'\" || traceback=\"Traceback (most recent call last):\n",
      "  File \"/opt/nuclio/_nuclio_wrapper.py\", line 272, in run_wrapper\n",
      "    args.trigger_name)\n",
      "  File \"/opt/nuclio/_nuclio_wrapper.py\", line 56, in __init__\n",
      "    self._context = nuclio_sdk.Context(self._logger, self._platform, worker_id, trigger_name)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/nuclio_sdk/context.py\", line 31, in __init__\n",
      "    self.trigger_name = self.trigger.name\n",
      "AttributeError: 'str' object has no attribute 'name'\n",
      "\"]\n",
      "Caught unhandled exception while initializing [err=\"'str' object has no attribute 'name'\" || traceback=\"Traceback (most recent call last):\n",
      "  File \"/opt/nuclio/_nuclio_wrapper.py\", line 272, in run_wrapper\n",
      "    args.trigger_name)\n",
      "  File \"/opt/nuclio/_nuclio_wrapper.py\", line 56, in __init__\n",
      "    self._context = nuclio_sdk.Context(self._logger, self._platform, worker_id, trigger_name)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/nuclio_sdk/context.py\", line 31, in __init__\n",
      "    self.trigger_name = self.trigger.name\n",
      "AttributeError: 'str' object has no attribute 'name'\n",
      "\"]\n",
      "Failed to read from connection [name=\"processor.http.w0.python.logger\" || err=\"EOF\"]\n",
      "Failed to read from connection [err=\"EOF\" || name=\"processor.http.w4.python.logger\"]\n",
      "Caught unhandled exception while initializing [err=\"'str' object has no attribute 'name'\" || traceback=\"Traceback (most recent call last):\n",
      "  File \"/opt/nuclio/_nuclio_wrapper.py\", line 272, in run_wrapper\n",
      "    args.trigger_name)\n",
      "  File \"/opt/nuclio/_nuclio_wrapper.py\", line 56, in __init__\n",
      "    self._context = nuclio_sdk.Context(self._logger, self._platform, worker_id, trigger_name)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/nuclio_sdk/context.py\", line 31, in __init__\n",
      "    self.trigger_name = self.trigger.name\n",
      "AttributeError: 'str' object has no attribute 'name'\n",
      "\"]\n",
      "Caught unhandled exception while initializing [err=\"'str' object has no attribute 'name'\" || traceback=\"Traceback (most recent call last):\n",
      "  File \"/opt/nuclio/_nuclio_wrapper.py\", line 272, in run_wrapper\n",
      "    args.trigger_name)\n",
      "  File \"/opt/nuclio/_nuclio_wrapper.py\", line 56, in __init__\n",
      "    self._context = nuclio_sdk.Context(self._logger, self._platform, worker_id, trigger_name)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/nuclio_sdk/context.py\", line 31, in __init__\n",
      "    self.trigger_name = self.trigger.name\n",
      "AttributeError: 'str' object has no attribute 'name'\n",
      "\"]\n",
      "Caught unhandled exception while initializing [traceback=\"Traceback (most recent call last):\n",
      "  File \"/opt/nuclio/_nuclio_wrapper.py\", line 272, in run_wrapper\n",
      "    args.trigger_name)\n",
      "  File \"/opt/nuclio/_nuclio_wrapper.py\", line 56, in __init__\n",
      "    self._context = nuclio_sdk.Context(self._logger, self._platform, worker_id, trigger_name)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/nuclio_sdk/context.py\", line 31, in __init__\n",
      "    self.trigger_name = self.trigger.name\n",
      "AttributeError: 'str' object has no attribute 'name'\n",
      "\" || err=\"'str' object has no attribute 'name'\"]\n",
      "Failed to read from connection [err=\"EOF\" || name=\"processor.http.w7.python.logger\"]\n",
      "Failed to read from connection [name=\"processor.http.w3.python.logger\" || err=\"EOF\"]\n",
      "Failed to read from connection [name=\"processor.http.w1.python.logger\" || err=\"EOF\"]\n",
      "[E 200216 15:01:42 logger:106] Caught unhandled exception while initializing\n",
      "[E 200216 15:01:42 logger:106] Caught unhandled exception while initializing\n",
      "Caught unhandled exception while initializing [err=\"'str' object has no attribute 'name'\" || traceback=\"Traceback (most recent call last):\n",
      "  File \"/opt/nuclio/_nuclio_wrapper.py\", line 272, in run_wrapper\n",
      "    args.trigger_name)\n",
      "  File \"/opt/nuclio/_nuclio_wrapper.py\", line 56, in __init__\n",
      "    self._context = nuclio_sdk.Context(self._logger, self._platform, worker_id, trigger_name)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/nuclio_sdk/context.py\", line 31, in __init__\n",
      "    self.trigger_name = self.trigger.name\n",
      "AttributeError: 'str' object has no attribute 'name'\n",
      "\"]\n",
      "Caught unhandled exception while initializing [err=\"'str' object has no attribute 'name'\" || traceback=\"Traceback (most recent call last):\n",
      "  File \"/opt/nuclio/_nuclio_wrapper.py\", line 272, in run_wrapper\n",
      "    args.trigger_name)\n",
      "  File \"/opt/nuclio/_nuclio_wrapper.py\", line 56, in __init__\n",
      "    self._context = nuclio_sdk.Context(self._logger, self._platform, worker_id, trigger_name)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/nuclio_sdk/context.py\", line 31, in __init__\n",
      "    self.trigger_name = self.trigger.name\n",
      "AttributeError: 'str' object has no attribute 'name'\n",
      "\"]\n",
      "Failed to read from connection [name=\"processor.http.w5.python.logger\" || err=\"EOF\"]\n",
      "Failed to read from connection [err=\"EOF\" || name=\"processor.http.w2.python.logger\"]\n"
     ]
    },
    {
     "ename": "DeployError",
     "evalue": "cannot deploy ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDeployError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a6ae5dec0e5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maddr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pythonlibs/jupyter-1/lib/python3.6/site-packages/mlrun/runtimes/function.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, dashboard, project, tag, kind)\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdashboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                 \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                 create_new=True)\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pythonlibs/jupyter-1/lib/python3.6/site-packages/nuclio/deploy.py\u001b[0m in \u001b[0;36mdeploy_config\u001b[0;34m(config, dashboard_url, name, project, tag, verbose, create_new)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ready'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ERROR: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mDeployError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cannot deploy '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'done %s %s, function address: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDeployError\u001b[0m: cannot deploy "
     ]
    }
   ],
   "source": [
    "addr = fn.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"test-model-server\"></a>\n",
    "### **test our model server using HTTP request**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "resp = requests.post(addr + '/classifier_gen/predict', json=event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp.__dict__['_content'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[back to top](#top)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
